{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf30b77-0cba-4bb6-9280-d7b83de135d7",
   "metadata": {},
   "source": [
    "### Inventory Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ef7a5-8000-489e-b33f-dabbaa300f86",
   "metadata": {},
   "source": [
    "### Sessions Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fb3436-1def-4bad-8a30-e3caf49b9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported the dataset to 'Cleaned_Movie_Sessions_with_Session_Hours.csv'\n",
      "‚úÖ Exported the exploded dataset to 'Exploded_Sessions_with_Session_Hours.csv'\n",
      "‚úÖ Exported the aggregated dataset to 'Aggregated_Sessions1.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the movie sessions data\n",
    "sessions_path = \"Movie_sessions.xlsx\"\n",
    "# sessions_df = pd.read_excel(sessions_path, sheet_name=\"Sheet1\")\n",
    "sessions_df = pd.read_excel(sessions_path)\n",
    "sessions_df = pd.read_excel(\n",
    "    sessions_path,\n",
    "    sheet_name=\"Sheet1\",\n",
    "    engine=\"openpyxl\"\n",
    ")\n",
    "sessions_df = sessions_df[sessions_df[\"Session Audio Language\"] != \"Overall Result\"]\n",
    "sessions_df = sessions_df[sessions_df[\"Duration\"] != \"960 MIN\"]\n",
    "\n",
    "# Step 1: Convert 'Duration' to numeric (strip ' MIN')\n",
    "sessions_df[\"Duration\"] = sessions_df[\"Duration\"].str.replace(\" MIN\", \"\").astype(int)\n",
    "\n",
    "# Create a single 'Duration Category' column based on defined ranges\n",
    "sessions_df[\"Duration Category\"] = pd.cut(\n",
    "    sessions_df[\"Duration\"],\n",
    "    bins=[0, 90, 120, float('inf')],\n",
    "    labels=[\"Short\", \"Medium\", \"Long\"],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "\n",
    "# Create a function to generate all session hours based on the starting hour and duration\n",
    "def get_session_hours(row):\n",
    "    start_hour = int(row['Session Hour'])  # Convert start hour to integer\n",
    "    duration = row['Duration']  # Duration is already in minutes\n",
    "    \n",
    "    # Calculate the end hour by adding duration (converted to hours) to start hour\n",
    "    end_hour = start_hour + (duration // 60)  # Calculate end hour (ignoring minutes for simplicity)\n",
    "    \n",
    "    # Generate the list of hours the movie will run (from start hour to end hour)\n",
    "    session_hours = list(range(start_hour, end_hour + 1))\n",
    "    return session_hours\n",
    "\n",
    "#Apply the function to get session hours\n",
    "sessions_df['Session Hours'] = sessions_df.apply(get_session_hours, axis=1)\n",
    "\n",
    "###################################################cleaned movie session with session hours\n",
    "# Export the dataframe with the 'Session Hours' column to a CSV file\n",
    "sessions_df.to_csv(\"Cleaned_Movie_Sessions_with_Session_Hours.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Exported the dataset to 'Cleaned_Movie_Sessions_with_Session_Hours.csv'\")\n",
    "##################################################\n",
    "\n",
    "# Drop the 'Duration' column since we have the 'Session Hours' column now\n",
    "sessions_df = sessions_df.drop(columns=[\"Duration\"])\n",
    "\n",
    "\n",
    "# One-hot encode categorical columns: 'Session Audio Language', 'Genre', 'Censor Rating', 'Duration Category'\n",
    "dummies = pd.get_dummies(\n",
    "    sessions_df[[\"Session Audio Language\", \"Genre\", \"Censor Rating\", \"Duration Category\"]],\n",
    "    prefix=[\"Lang\", \"Genre\", \"Rating\", \"Duration\"]\n",
    ")\n",
    "\n",
    "# Convert the boolean columns to 0/1\n",
    "dummies = dummies.astype(int)\n",
    "\n",
    "# Add the one-hot encoded columns to the original dataframe\n",
    "sessions_df = pd.concat([sessions_df, dummies], axis=1)\n",
    "\n",
    "# Drop the original categorical columns after one-hot encoding\n",
    "sessions_df = sessions_df.drop(columns=[\"Session Audio Language\", \"Genre\", \"Censor Rating\", \"Duration Category\"])\n",
    "#####################################################\n",
    "sessions_df.to_csv(\"Cleaned_Movie_Sessions_with_Session_Hours.csv\", index=False)\n",
    "\n",
    "\n",
    "# Step 1: Create a function to generate the exploded dataframe based on session hours\n",
    "def explode_session_hours(df):\n",
    "    exploded_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        session_hours = row['Session Hours']  # Get the list of session hours for this row\n",
    "        total_admits = row['Total Admits']  # Get the total admits\n",
    "        one_hot_columns = row.drop(['Session Date', 'Session Hour', 'Total Admits', 'Session Hours'])  # Get the one-hot encoded columns\n",
    "        \n",
    "        # For each session hour in the list, create a new row\n",
    "        for i, hour in enumerate(session_hours):\n",
    "            # If it's the first hour, keep the total admits, otherwise set it to 0\n",
    "            if i == 0:\n",
    "                new_row = row.copy()  # Keep all original data for the first session hour\n",
    "                new_row['Session Hour'] = hour\n",
    "                exploded_rows.append(new_row)\n",
    "            else:\n",
    "                # For subsequent hours, set total admits and one-hot encoded columns to 0\n",
    "                new_row = row.copy()\n",
    "                new_row['Session Hour'] = hour\n",
    "                new_row['Total Admits'] = 0\n",
    "                new_row[one_hot_columns.index] = 0  # Set all one-hot columns to 0\n",
    "                exploded_rows.append(new_row)\n",
    "    \n",
    "    # Create a new dataframe from the exploded rows\n",
    "    exploded_df = pd.DataFrame(exploded_rows).reset_index(drop=True)\n",
    "    return exploded_df\n",
    "\n",
    "# Step 2: Apply the explode function to create the final dataframe\n",
    "sessions_exploded_df = explode_session_hours(sessions_df)\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Step 4: Export the exploded dataframe to CSV for later use\n",
    "sessions_exploded_df.to_csv(\"Exploded_Sessions_with_Session_Hours.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Exported the exploded dataset to 'Exploded_Sessions_with_Session_Hours.csv'\")\n",
    "########################################\n",
    "\n",
    "\n",
    "# Step 1: Drop the 'Session Hours' and 'Film' columns after exploding the data\n",
    "sessions_exploded_df = sessions_exploded_df.drop(columns=[\"Session Hours\", \"Film\"])\n",
    "\n",
    "# Aggregate by 'Session Date' and 'Session Hour', summing the relevant columns (and all other columns)\n",
    "aggregated_sessions_df = sessions_exploded_df.groupby(['Session Date', 'Session Hour']).agg(\n",
    "    {col: 'sum' for col in sessions_exploded_df.columns if col not in ['Session Date', 'Session Hour']}).reset_index()\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Step 4: Export the aggregated data to a CSV file\n",
    "aggregated_sessions_df.to_csv(\"Aggregated_Sessions1.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Exported the aggregated dataset to 'Aggregated_Sessions1.csv'\")\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075fa5c4-3a5e-488f-81d3-3f0274888096",
   "metadata": {},
   "source": [
    "### Merging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85a29bb-6d66-46da-a42e-9b9934d32113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported the merged dataset to 'Merged_Aggregated_Sessions_with_Revenue_Left_Join.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Session Date' in aggregated_sessions_df to datetime (standardize format)\n",
    "aggregated_sessions_df['Session Date'] = pd.to_datetime(\n",
    "    aggregated_sessions_df['Session Date'], \n",
    "    format='%d.%m.%Y',  # Specify the format as dd.mm.yyyy \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "aggregated_sessions_df.columns\n",
    "\n",
    "# Drop the redundant 'Date' column after the merge, since we already have 'Session Date'\n",
    "merged_data = aggregated_sessions_df\n",
    "\n",
    "#########################################\n",
    "# Export the merged data to a CSV file for further use\n",
    "merged_data.to_csv(\"Merged_Aggregated_Sessions_with_Revenue_Left_Join.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Exported the merged dataset to 'Merged_Aggregated_Sessions_with_Revenue_Left_Join.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7896a-f486-4d9f-a8a3-7ff3d959ae2f",
   "metadata": {},
   "source": [
    "### Sales forecasting Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef0d4ef1-3b63-44d1-9639-13f447a57556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All dates converted successfully.\n",
      "‚úÖ Data exported to 'my_validation_data_inventory.csv'\n",
      "‚úÖ Data exported to 'forecasting_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Merged_Aggregated_Sessions_with_Revenue_Left_Join.csv\")\n",
    "# üïí Convert 'Session Date' to datetime\n",
    "df['Session Date'] = pd.to_datetime(df['Session Date'], errors='coerce')\n",
    "#######################################################################\n",
    "\n",
    "# üö® Check for any conversion issues (NaT values)\n",
    "conversion_issues = df[df['Session Date'].isnull()]\n",
    "if not conversion_issues.empty:\n",
    "    print(\"\\n‚ö†Ô∏è Conversion issues found:\")\n",
    "    print(conversion_issues)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All dates converted successfully.\")\n",
    "\n",
    "# üìÜ Extract day of week and month from 'Session Date'\n",
    "df['DayOfWeek'] = df['Session Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['Month'] = df['Session Date'].dt.month\n",
    "\n",
    "#####################################for inventory forecasting part#############\n",
    "# üíæ Export the updated DataFrame to CSV\n",
    "df.to_csv(\"my_validation_data_inventory.csv\", index=False)\n",
    "print(\"‚úÖ Data exported to 'my_validation_data_inventory.csv'\")\n",
    "\n",
    "#############################################The below line will need to be shifted below the export part in inventory forecasting part.. \n",
    "# df = df.drop(columns=['Session Date'])\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# üíæ Export the updated DataFrame to CSV\n",
    "df.to_csv(\"my_validation_data.csv\", index=False)\n",
    "print(\"‚úÖ Data exported to 'forecasting_data.csv'\")\n",
    "#################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22fb5c-529a-479e-ab90-557774dbcde5",
   "metadata": {},
   "source": [
    "### Validation with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e040fb1c-52f4-4ae2-8790-9d174ce79acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Missing features to ADD (19):\n",
      "['Lang_Assamese', 'Lang_Bengali', 'Lang_Chinese (Cantonese)', 'Lang_Filipino', 'Lang_Gujarati', 'Lang_Indonesian', 'Lang_Japanese', 'Lang_Maori', 'Lang_Not assigned', 'Lang_Thai', 'Lang_Urdu', 'Genre_FAMILY', 'Genre_GAMING', 'Genre_MUSIC', 'Genre_MUSICAL', 'Genre_MYSTERY', 'Genre_SCI-FI', 'Genre_TO BE ADVISED', 'Rating_CTC']\n",
      "üîç Extra features to DROP (4):\n",
      "['Session Date', 'Lang_Spanish', 'Lang_Swedish', 'Total Session Revenue']\n",
      "\n",
      "üî¢ Aligned feature matrix shape: (361, 56)\n",
      "\n",
      "‚Äî Newly added (zero‚Äêfilled) columns ‚Äî\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang_Assamese</th>\n",
       "      <th>Lang_Bengali</th>\n",
       "      <th>Lang_Chinese (Cantonese)</th>\n",
       "      <th>Lang_Filipino</th>\n",
       "      <th>Lang_Gujarati</th>\n",
       "      <th>Lang_Indonesian</th>\n",
       "      <th>Lang_Japanese</th>\n",
       "      <th>Lang_Maori</th>\n",
       "      <th>Lang_Not assigned</th>\n",
       "      <th>Lang_Thai</th>\n",
       "      <th>Lang_Urdu</th>\n",
       "      <th>Genre_FAMILY</th>\n",
       "      <th>Genre_GAMING</th>\n",
       "      <th>Genre_MUSIC</th>\n",
       "      <th>Genre_MUSICAL</th>\n",
       "      <th>Genre_MYSTERY</th>\n",
       "      <th>Genre_SCI-FI</th>\n",
       "      <th>Genre_TO BE ADVISED</th>\n",
       "      <th>Rating_CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lang_Assamese  Lang_Bengali  Lang_Chinese (Cantonese)  Lang_Filipino  \\\n",
       "0              0             0                         0              0   \n",
       "1              0             0                         0              0   \n",
       "2              0             0                         0              0   \n",
       "3              0             0                         0              0   \n",
       "4              0             0                         0              0   \n",
       "\n",
       "   Lang_Gujarati  Lang_Indonesian  Lang_Japanese  Lang_Maori  \\\n",
       "0              0                0              0           0   \n",
       "1              0                0              0           0   \n",
       "2              0                0              0           0   \n",
       "3              0                0              0           0   \n",
       "4              0                0              0           0   \n",
       "\n",
       "   Lang_Not assigned  Lang_Thai  Lang_Urdu  Genre_FAMILY  Genre_GAMING  \\\n",
       "0                  0          0          0             0             0   \n",
       "1                  0          0          0             0             0   \n",
       "2                  0          0          0             0             0   \n",
       "3                  0          0          0             0             0   \n",
       "4                  0          0          0             0             0   \n",
       "\n",
       "   Genre_MUSIC  Genre_MUSICAL  Genre_MYSTERY  Genre_SCI-FI  \\\n",
       "0            0              0              0             0   \n",
       "1            0              0              0             0   \n",
       "2            0              0              0             0   \n",
       "3            0              0              0             0   \n",
       "4            0              0              0             0   \n",
       "\n",
       "   Genre_TO BE ADVISED  Rating_CTC  \n",
       "0                    0           0  \n",
       "1                    0           0  \n",
       "2                    0           0  \n",
       "3                    0           0  \n",
       "4                    0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Äî Sample predictions ‚Äî\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session Date</th>\n",
       "      <th>Session Hour</th>\n",
       "      <th>Total Admits</th>\n",
       "      <th>Lang_Chinese (Mandarin)</th>\n",
       "      <th>Lang_English</th>\n",
       "      <th>Lang_Hindi</th>\n",
       "      <th>Lang_Kannada</th>\n",
       "      <th>Lang_Korean</th>\n",
       "      <th>Lang_Malayalam</th>\n",
       "      <th>Lang_Nepali</th>\n",
       "      <th>...</th>\n",
       "      <th>Rating_M</th>\n",
       "      <th>Rating_MA15</th>\n",
       "      <th>Rating_PG</th>\n",
       "      <th>Rating_R18+</th>\n",
       "      <th>Duration_Short</th>\n",
       "      <th>Duration_Medium</th>\n",
       "      <th>Duration_Long</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Total Session Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>13</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Session Date  Session Hour  Total Admits  Lang_Chinese (Mandarin)  \\\n",
       "0   2025-02-01             9             7                        0   \n",
       "1   2025-02-01            10             9                        0   \n",
       "2   2025-02-01            11            23                        0   \n",
       "3   2025-02-01            12            27                        0   \n",
       "4   2025-02-01            13            68                        0   \n",
       "\n",
       "   Lang_English  Lang_Hindi  Lang_Kannada  Lang_Korean  Lang_Malayalam  \\\n",
       "0             2           0             0            0               0   \n",
       "1             2           0             0            0               0   \n",
       "2             3           0             0            0               0   \n",
       "3             5           1             0            0               0   \n",
       "4             4           0             0            0               1   \n",
       "\n",
       "   Lang_Nepali  ...  Rating_M  Rating_MA15  Rating_PG  Rating_R18+  \\\n",
       "0            0  ...         0            0          0            0   \n",
       "1            0  ...         0            2          1            0   \n",
       "2            0  ...         1            0          3            0   \n",
       "3            0  ...         1            1          3            0   \n",
       "4            0  ...         2            2          2            0   \n",
       "\n",
       "   Duration_Short  Duration_Medium  Duration_Long  DayOfWeek  Month  \\\n",
       "0               2                0              0          5      2   \n",
       "1               0                2              1          5      2   \n",
       "2               0                3              1          5      2   \n",
       "3               1                4              1          5      2   \n",
       "4               0                4              2          5      2   \n",
       "\n",
       "   Total Session Revenue  \n",
       "0                     22  \n",
       "1                    119  \n",
       "2                     70  \n",
       "3                    168  \n",
       "4                    270  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved predictions to my_validation_data.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Load your new sessions DataFrame (no Total Revenue col yet)\n",
    "df_val = pd.read_csv(\"my_validation_data.csv\")\n",
    "\n",
    "# 2) Split out features only\n",
    "#    (we'll add the predicted revenue back to df_val)\n",
    "X_val = df_val.copy()\n",
    "\n",
    "# 3) Load your pickled CatBoost model and feature list\n",
    "model          = joblib.load(\"best_catboost_model.pkl\")\n",
    "expected_feats = joblib.load(\"feature_list.pkl\")\n",
    "\n",
    "# 4) Identify and fix missing / extra features\n",
    "missing_feats = [f for f in expected_feats if f not in X_val.columns]\n",
    "extra_feats   = [f for f in X_val.columns if f not in expected_feats]\n",
    "\n",
    "print(f\"üîç Missing features to ADD ({len(missing_feats)}):\\n{missing_feats}\")\n",
    "print(f\"üîç Extra features to DROP ({len(extra_feats)}):\\n{extra_feats}\")\n",
    "\n",
    "# 5) Add any missing (zero‚Äêfill), drop extras\n",
    "for f in missing_feats:\n",
    "    X_val[f] = 0\n",
    "if extra_feats:\n",
    "    X_val.drop(columns=extra_feats, inplace=True)\n",
    "\n",
    "# 6) Reorder to match training columns\n",
    "X_val = X_val[expected_feats]\n",
    "print(f\"\\nüî¢ Aligned feature matrix shape: {X_val.shape}\")\n",
    "\n",
    "# 7) (Optional) peek at the zero‚Äêfilled columns\n",
    "if missing_feats:\n",
    "    print(\"\\n‚Äî Newly added (zero‚Äêfilled) columns ‚Äî\")\n",
    "    display(X_val[missing_feats].head())\n",
    "\n",
    "# 8) Predict Total Revenue\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# 9) Inject predictions back into your original df\n",
    "df_val[\"Total Session Revenue\"] = y_pred.round().astype(int)\n",
    "\n",
    "# 10) Show the first few rows\n",
    "print(\"\\n‚Äî Sample predictions ‚Äî\")\n",
    "display(df_val.head())\n",
    "\n",
    "# 11) Save out if you like\n",
    "df_val.to_csv(\"my_validation_data.csv\", index=False)\n",
    "print(\"‚úÖ Saved predictions to my_validation_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72286ad-641f-44ff-9f5e-a97b29a26bae",
   "metadata": {},
   "source": [
    "### Inventory Main preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8170562-91e0-48a6-ab20-206450f08e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "forecasting_df = pd.read_csv(\"my_validation_data.csv\")\n",
    "# Convert date columns to datetime if not already\n",
    "# forecasting_df[\"Session Date\"] = pd.to_datetime(forecasting_df[\"Session Date\"])\n",
    "merged_df = forecasting_df\n",
    "\n",
    "# Drop duplicate columns from right side\n",
    "# merged_df = merged_df.drop(columns=[\"Transaction Date\", \"Transaction Hour\"])\n",
    "\n",
    "########################################################################\n",
    "merged_df.to_csv(\"basketanalysis.csv\", index=False)\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8cf3db6-044f-4cdd-972a-81123852effb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Session Date', 'Session Hour', 'Total Admits',\n",
       "       'Lang_Chinese (Mandarin)', 'Lang_English', 'Lang_Hindi', 'Lang_Kannada',\n",
       "       'Lang_Korean', 'Lang_Malayalam', 'Lang_Nepali', 'Lang_No Subtitles',\n",
       "       'Lang_Punjabi', 'Lang_Spanish', 'Lang_Swedish', 'Lang_Tamil',\n",
       "       'Lang_Telugu', 'Lang_Vietnamese', 'Genre_ACTION', 'Genre_ADVENTURE',\n",
       "       'Genre_ANIMATION', 'Genre_BIOGRAPHY', 'Genre_COMEDY', 'Genre_CRIME',\n",
       "       'Genre_DOCUMENTARY', 'Genre_DRAMA', 'Genre_FANTASY', 'Genre_HORROR',\n",
       "       'Genre_ROMANCE', 'Genre_THRILLER', 'Rating_E', 'Rating_G', 'Rating_M',\n",
       "       'Rating_MA15', 'Rating_PG', 'Rating_R18+', 'Duration_Short',\n",
       "       'Duration_Medium', 'Duration_Long', 'DayOfWeek', 'Month',\n",
       "       'Total Session Revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44854a03-9db2-41b8-93d5-2c7baf1877f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Adding 19 missing features: ['Lang_Assamese', 'Lang_Bengali', 'Lang_Chinese (Cantonese)', 'Lang_Filipino', 'Lang_Gujarati', 'Lang_Indonesian', 'Lang_Japanese', 'Lang_Maori', 'Lang_Not assigned', 'Lang_Thai', 'Lang_Urdu', 'Genre_FAMILY', 'Genre_GAMING', 'Genre_MUSIC', 'Genre_MUSICAL', 'Genre_MYSTERY', 'Genre_SCI-FI', 'Genre_TO BE ADVISED', 'Rating_CTC']\n",
      "üóëÔ∏è Dropping 3 extra columns: ['Session Date', 'Lang_Spanish', 'Lang_Swedish']\n",
      "üî¢ Aligned feature matrix shape: (361, 57)\n",
      "\n",
      "‚Äî Sample sessions with predicted item‚Äêclass counts ‚Äî\n",
      "   Session Hour  Total Admits  Lang_Assamese  SNACK - CHIPS  FOOD - VJUNIOR  \\\n",
      "0             9             7              0              1               1   \n",
      "1            10             9              0              0               1   \n",
      "2            11            23              0              0               1   \n",
      "3            12            27              0              0               2   \n",
      "4            13            68              0              1               2   \n",
      "\n",
      "   ICE CREAMS - OTHER  DRINKS - EXTRA LARGE  DRINKS  DRINKS - SMALL  \\\n",
      "0                   0                     0       1               1   \n",
      "1                   0                     0       4               1   \n",
      "2                   0                     0       6               2   \n",
      "3                   1                     0       5               3   \n",
      "4                   1                     1      11               5   \n",
      "\n",
      "   DRINKS - MEDIUM  ICE CREAMS - CHOC TO  DRINKS - NO ICE  DRINKS - LARGE  \\\n",
      "0                0                     2                1               2   \n",
      "1                2                     3                1               3   \n",
      "2                1                     3                2               2   \n",
      "3                2                     6                1               7   \n",
      "4                5                    11                5              12   \n",
      "\n",
      "   POPCORN  \n",
      "0        4  \n",
      "1       10  \n",
      "2        9  \n",
      "3       15  \n",
      "4       29  \n",
      "‚úÖ Saved predictions for 361 sessions to 'predicted_item_sales.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# 1) Load your raw sessions data (no item‚Äêclass columns yet)\n",
    "df_val = pd.read_csv(\"basketanalysis.csv\")  # replace with your actual file\n",
    "\n",
    "# 2) Load your trained multi‚Äêitem model and its column lists\n",
    "model        = joblib.load(\"best_catboost_model_run3.pkl\")\n",
    "feature_cols = joblib.load(\"feature_cols_run3.pkl\")\n",
    "target_cols  = joblib.load(\"target_cols_run3.pkl\")\n",
    "\n",
    "# 3) Align features: add any missing, drop any extras\n",
    "missing_feats = [f for f in feature_cols if f not in df_val.columns]\n",
    "if missing_feats:\n",
    "    print(f\"üîç Adding {len(missing_feats)} missing features: {missing_feats}\")\n",
    "    for f in missing_feats:\n",
    "        df_val[f] = 0\n",
    "\n",
    "extra_feats = [c for c in df_val.columns if c not in feature_cols]\n",
    "if extra_feats:\n",
    "    print(f\"üóëÔ∏è Dropping {len(extra_feats)} extra columns: {extra_feats}\")\n",
    "    # df_val.drop(columns=extra_feats, inplace=True)\n",
    "\n",
    "# 4) Build the feature matrix in the exact training order\n",
    "X_val = df_val[feature_cols].copy()\n",
    "print(f\"üî¢ Aligned feature matrix shape: {X_val.shape}\")\n",
    "\n",
    "# 5) Predict each item‚Äêclass count\n",
    "y_pred = model.predict(X_val)  # returns array of shape (n_rows, n_targets)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=target_cols, index=df_val.index)\n",
    "\n",
    "# 6) Round to integers\n",
    "y_pred_df = y_pred_df.round().astype(int)\n",
    "\n",
    "# 7) Inject predictions back into your original DataFrame\n",
    "for col in target_cols:\n",
    "    df_val[col] = y_pred_df[col]\n",
    "\n",
    "# 8) (Optional) Inspect a few rows\n",
    "print(\"\\n‚Äî Sample sessions with predicted item‚Äêclass counts ‚Äî\")\n",
    "print(df_val[feature_cols[:3] + target_cols].head())  # show first 3 feature cols + all targets\n",
    "\n",
    "# 9) Save out full predictions\n",
    "df_val.to_csv(\"predicted_item_sales.csv\", index=False)\n",
    "print(f\"‚úÖ Saved predictions for {len(df_val)} sessions to 'predicted_item_sales.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4b18e-a52e-48a3-a8d1-169a4c1c461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab8f40-2533-46a7-88e2-c91148b6faaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
