{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589934ab-ffe7-403c-8d4a-9f071034e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas openpyxl xlrd mlxtend implicit tqdm threadpoolctl matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363399d1-3621-4d61-9523-8517b4f308d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Core Imports, Constants, Dataclasses, and DataManager Definition (with Recency Weighting)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import hashlib\n",
    "import json\n",
    "import warnings\n",
    "import scipy.sparse as sp\n",
    "from tqdm.auto import tqdm\n",
    "import implicit\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "from datetime import datetime, timedelta # timedelta is used\n",
    "from dataclasses import dataclass, replace as dc_replace\n",
    "\n",
    "VERBOSE_LOGGING = False\n",
    "\n",
    "warnings.simplefilter(\"ignore\", pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered\", category=RuntimeWarning, module=\"mlxtend.frequent_patterns.association_rules\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"executing.executing\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"ast\")\n",
    "\n",
    "try:\n",
    "    from threadpoolctl import threadpool_limits\n",
    "    threadpool_limits(1, \"blas\")\n",
    "    if VERBOSE_LOGGING: print(\"BLAS threadpool limit set to 1.\")\n",
    "except ImportError:\n",
    "    if VERBOSE_LOGGING: print(\"Consider 'threadpoolctl' for 'implicit'.\")\n",
    "except Exception as e:\n",
    "    if VERBOSE_LOGGING: print(f\"Could not set BLAS limits: {e}\")\n",
    "\n",
    "# Constants and Paths Configuration\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "CACHE_VERSION_PREFIX = \"v1.1\" \n",
    "\n",
    "# Define the root path for inputs. Assumes the notebook is run from the project root.\n",
    "INPUT_DATA_DIR = Path(\"Input Datasets/\")\n",
    "\n",
    "# Define paths to the specific dataset files within the input directory.\n",
    "# The Streamlit app will also use these same paths.\n",
    "TRAINING_DATA_PATH = INPUT_DATA_DIR / \"train_dataset.xlsx\"\n",
    "HOLDOUT_DATA_PATH = INPUT_DATA_DIR / \"test_dataset.xlsx\"\n",
    "INVENTORY_DATA_PATH = INPUT_DATA_DIR / \"inventory_transactions_clean.xlsx\"\n",
    "\n",
    "# Define the output directory for cached models and rules.\n",
    "MODELS_OUTPUT_DIR = Path(\"models\")\n",
    "MODELS_OUTPUT_DIR.mkdir(exist_ok=True) # Ensure the directory exists\n",
    "\n",
    "ITEM_CLASS_PREFIX = \"item_class_\"\n",
    "SKU_NAME_PREFIX = \"product_name_\"\n",
    "CUSTOMER_SEGMENT_PREFIXES = {\"genre_\": \"Genre\", \"slot_\": \"Slot\", \"language_\": \"Language\", \"rating_\": \"Rating\", \"duration_category_\": \"Duration\"}\n",
    "\n",
    "MIN_SUP = 0.01\n",
    "MIN_CONF = 0.05\n",
    "MIN_LIFT = 1.2\n",
    "MIN_ROWS_SEG = 10\n",
    "MAX_ROW_REP = 8\n",
    "\n",
    "RECENCY_WEIGHTING_CONFIG = {\n",
    "    \"apply\": True,\n",
    "    \"timestamp_col\": \"timestamp\",\n",
    "    \"tiers\": [\n",
    "        {\"months_ago_end\": 3, \"weight_factor\": 1.0},\n",
    "        {\"months_ago_end\": 6, \"weight_factor\": 0.8},\n",
    "        {\"months_ago_end\": 12, \"weight_factor\": 0.6},\n",
    "        {\"months_ago_end\": 24, \"weight_factor\": 0.4},\n",
    "        {\"months_ago_end\": float('inf'), \"weight_factor\": 0.2}\n",
    "    ]\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class RuleParams:\n",
    "    min_support:   float = MIN_SUP\n",
    "    min_confidence:float = MIN_CONF\n",
    "    min_lift:      float = MIN_LIFT\n",
    "    max_len_global:int   = 0\n",
    "    max_itemset_len_segment: int = 2\n",
    "\n",
    "@dataclass\n",
    "class RecParams:\n",
    "    top_classes: int = 5\n",
    "    skus_per_cls: int = 3\n",
    "\n",
    "@dataclass\n",
    "class EvaluationKValueParam:\n",
    "    k_for_rank_metrics: int = 10\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        self._df_training_cache = None\n",
    "        self._df_holdout_cache = None\n",
    "        self._df_inventory_cache = None\n",
    "        self._sku_to_class_map = None\n",
    "        self._class_to_sku_map_training = None\n",
    "        self._masks_training = None\n",
    "        self._masks_holdout = None\n",
    "\n",
    "    def _load_inventory_data(self):\n",
    "        if self._df_inventory_cache is None:\n",
    "            if VERBOSE_LOGGING: print(f\"Loading inventory data from: {INVENTORY_DATA_PATH}...\")\n",
    "            self._df_inventory_cache = pd.read_excel(INVENTORY_DATA_PATH).drop_duplicates(subset=\"product_name\", keep=\"first\")\n",
    "        return self._df_inventory_cache\n",
    "\n",
    "    @property\n",
    "    def sku2cls(self):\n",
    "        if self._sku_to_class_map is None:\n",
    "            inventory_df = self._load_inventory_data()\n",
    "            if VERBOSE_LOGGING: print(\"Generating SKU to Item Class mapping...\")\n",
    "            self._sku_to_class_map = inventory_df.set_index(\"product_name\")[\"item_class\"].str.upper().to_dict()\n",
    "        return self._sku_to_class_map\n",
    "\n",
    "    def get_class_to_sku_column_mapping_for_df(self, df_source: pd.DataFrame):\n",
    "        sku_to_class = self.sku2cls\n",
    "        class_to_sku_cols = {}\n",
    "        for col_name in df_source.filter(like=SKU_NAME_PREFIX).columns:\n",
    "            sku_name_only = col_name[len(SKU_NAME_PREFIX):]\n",
    "            item_class = sku_to_class.get(sku_name_only)\n",
    "            if item_class is not None: class_to_sku_cols.setdefault(item_class, []).append(col_name)\n",
    "        return class_to_sku_cols\n",
    "\n",
    "    def _load_training_with_recency_weights(self) -> pd.DataFrame:\n",
    "        if self._df_training_cache is None:\n",
    "            if VERBOSE_LOGGING: print(f\"Loading and weighting training data from: {TRAINING_DATA_PATH}...\")\n",
    "            df = pd.read_excel(TRAINING_DATA_PATH, parse_dates=[RECENCY_WEIGHTING_CONFIG[\"timestamp_col\"]])\n",
    "            if RECENCY_WEIGHTING_CONFIG[\"timestamp_col\"] not in df.columns:\n",
    "                raise ValueError(f\"Training data DataFrame must contain a '{RECENCY_WEIGHTING_CONFIG['timestamp_col']}' column.\")\n",
    "\n",
    "            if RECENCY_WEIGHTING_CONFIG[\"apply\"]:\n",
    "                ts_col = RECENCY_WEIGHTING_CONFIG[\"timestamp_col\"]\n",
    "                max_date = df[ts_col].max()\n",
    "                \n",
    "                # --- CORRECTED AGE IN MONTHS CALCULATION ---\n",
    "                # Calculate difference in days, then divide by average days in a month\n",
    "                days_diff = (max_date - df[ts_col]).dt.days\n",
    "                df[\"age_in_months\"] = (days_diff / 30.4375).fillna(0).astype(int) # Use average days\n",
    "                # --- END CORRECTION ---\n",
    "\n",
    "                df[\"__recency_weight\"] = RECENCY_WEIGHTING_CONFIG[\"tiers\"][-1][\"weight_factor\"]\n",
    "                for tier in sorted(RECENCY_WEIGHTING_CONFIG[\"tiers\"], key=lambda x: x[\"months_ago_end\"]):\n",
    "                    df.loc[df[\"age_in_months\"] < tier[\"months_ago_end\"], \"__recency_weight\"] = tier[\"weight_factor\"]\n",
    "                if VERBOSE_LOGGING:\n",
    "                    print(f\"Applied recency weights. Min: {df['__recency_weight'].min()}, Max: {df['__recency_weight'].max()}\")\n",
    "            else:\n",
    "                df[\"__recency_weight\"] = 1.0\n",
    "                if VERBOSE_LOGGING: print(\"Recency weighting is OFF for training data.\")\n",
    "            \n",
    "            self._df_training_cache = df\n",
    "        return self._df_training_cache\n",
    "\n",
    "    def _load_holdout_data(self):\n",
    "        if self._df_holdout_cache is None:\n",
    "            if VERBOSE_LOGGING: print(f\"Loading holdout data from: {HOLDOUT_DATA_PATH}...\")\n",
    "            self._df_holdout_cache = pd.read_excel(HOLDOUT_DATA_PATH, parse_dates=[RECENCY_WEIGHTING_CONFIG[\"timestamp_col\"]])\n",
    "            if \"__recency_weight\" not in self._df_holdout_cache.columns:\n",
    "                 self._df_holdout_cache[\"__recency_weight\"] = 1.0\n",
    "        return self._df_holdout_cache\n",
    "\n",
    "    def get_dataframe(self, data_type=\"training\") -> pd.DataFrame:\n",
    "        if data_type == \"training\":\n",
    "            return self._load_training_with_recency_weights().copy()\n",
    "        elif data_type == \"holdout\":\n",
    "            return self._load_holdout_data().copy()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data_type: must be 'training' or 'holdout'\")\n",
    "\n",
    "    def _generate_segment_masks_for_df(self, df_source: pd.DataFrame):\n",
    "        segment_masks = {}\n",
    "        for raw_prefix, display_label in CUSTOMER_SEGMENT_PREFIXES.items():\n",
    "            for col_name in df_source.columns:\n",
    "                if col_name.startswith(raw_prefix):\n",
    "                    mask = df_source[col_name].gt(0)\n",
    "                    if mask.sum() >= MIN_ROWS_SEG:\n",
    "                        segment_value_name = col_name[len(raw_prefix):].replace('_',' ').title()\n",
    "                        mask_key = f\"{display_label} Â· {segment_value_name}\"\n",
    "                        segment_masks[mask_key] = mask\n",
    "        return segment_masks\n",
    "\n",
    "    def get_segment_masks(self, data_type=\"training\"):\n",
    "        df_for_masks = self.get_dataframe(data_type)\n",
    "        cache_attr = f\"_masks_{data_type}\"\n",
    "\n",
    "        current_masks = getattr(self, cache_attr, None)\n",
    "        if current_masks is None:\n",
    "            if VERBOSE_LOGGING: print(f\"Generating segment masks for {data_type} data...\")\n",
    "            current_masks = self._generate_segment_masks_for_df(df_for_masks)\n",
    "            setattr(self, cache_attr, current_masks)\n",
    "        return current_masks\n",
    "\n",
    "    @property\n",
    "    def cls2sku_train(self):\n",
    "        if self._class_to_sku_map_training is None:\n",
    "             if VERBOSE_LOGGING: print(\"Generating Class to SKU column mapping (based on training data)...\")\n",
    "             self._class_to_sku_map_training = self.get_class_to_sku_column_mapping_for_df(self.get_dataframe(\"training\"))\n",
    "        return self._class_to_sku_map_training\n",
    "\n",
    "data_manager_global = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f480b2-6a7d-4a96-b77e-9cd5d14f2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper Functions\n",
    "def ctx_hash(ctx: dict, params_for_hash: dict = None) -> str:\n",
    "    normalized_ctx = {k: sorted(v) if isinstance(v, list) else v for k, v in ctx.items()}\n",
    "    context_json_string = json.dumps(normalized_ctx, sort_keys=True)\n",
    "    params_json_string = json.dumps(params_for_hash, sort_keys=True) if params_for_hash else \"\"\n",
    "    \n",
    "    recency_config_tag_part = \"\"\n",
    "    if RECENCY_WEIGHTING_CONFIG[\"apply\"]:\n",
    "        recency_config_tag_part = hashlib.md5(json.dumps(RECENCY_WEIGHTING_CONFIG, sort_keys=True).encode()).hexdigest()[:6]\n",
    "\n",
    "    full_string_to_hash = f\"{CACHE_VERSION_PREFIX}{context_json_string}{params_json_string}{recency_config_tag_part}\"\n",
    "    return hashlib.md5(full_string_to_hash.encode()).hexdigest()[:10]\n",
    "\n",
    "def subset_dataframe_by_context(source_df: pd.DataFrame, segment_masks: dict, context_criteria: dict) -> pd.DataFrame:\n",
    "    if not context_criteria:\n",
    "        return source_df.copy()\n",
    "    combined_filter_mask = pd.Series(True, index=source_df.index)\n",
    "    for segment_type, segment_values in context_criteria.items():\n",
    "        current_segment_values = segment_values if isinstance(segment_values, list) else [segment_values]\n",
    "        type_specific_or_mask = pd.Series(False, index=source_df.index)\n",
    "        any_value_matched_for_type = False\n",
    "        for single_value in current_segment_values:\n",
    "            mask_key_candidate = f\"{segment_type} Â· {str(single_value).replace('_', ' ').title()}\"\n",
    "            current_value_mask = segment_masks.get(mask_key_candidate)\n",
    "            if current_value_mask is None:\n",
    "                for available_mask_key in segment_masks.keys():\n",
    "                    if segment_type.lower() in available_mask_key.lower() and \\\n",
    "                       str(single_value).lower() in available_mask_key.lower() and \\\n",
    "                       available_mask_key.startswith(f\"{segment_type} Â·\"):\n",
    "                        current_value_mask = segment_masks[available_mask_key]\n",
    "                        if VERBOSE_LOGGING: print(f\"Info: Matched context '{segment_type}:{single_value}' to mask '{available_mask_key}' via fallback.\")\n",
    "                        break\n",
    "            if current_value_mask is not None:\n",
    "                type_specific_or_mask |= current_value_mask\n",
    "                any_value_matched_for_type = True\n",
    "        if not any_value_matched_for_type and current_segment_values:\n",
    "            available_keys_sample_str = \", \".join(list(segment_masks.keys())[:5]) + \"...\" if len(segment_masks) > 5 else \", \".join(list(segment_masks.keys()))\n",
    "            raise KeyError(f\"No valid masks for segment type '{segment_type}' with values {current_segment_values}. \"\n",
    "                           f\"Attempted keys like '{mask_key_candidate}'. Available mask keys: {available_keys_sample_str}\")\n",
    "        if any_value_matched_for_type:\n",
    "            combined_filter_mask &= type_specific_or_mask\n",
    "    return source_df.loc[combined_filter_mask].copy()\n",
    "\n",
    "def create_boolean_basket_with_row_replication(\n",
    "    ctx_df: pd.DataFrame,\n",
    "    item_prefix: str,\n",
    "    cap: int = MAX_ROW_REP\n",
    ") -> pd.DataFrame:\n",
    "    qty_df = ctx_df.filter(like=item_prefix).astype(int)\n",
    "    if qty_df.empty:\n",
    "        return pd.DataFrame(columns=qty_df.columns, dtype=bool)\n",
    "\n",
    "    total_items_per_row = qty_df.sum(axis=1).to_numpy()\n",
    "    \n",
    "    if \"__recency_weight\" not in ctx_df.columns:\n",
    "        if VERBOSE_LOGGING: print(\"Warning: '__recency_weight' not found in df for basket. Uniform weight 1 applied.\")\n",
    "        rec_weight = np.ones_like(total_items_per_row, dtype=float)\n",
    "    else:\n",
    "        rec_weight = ctx_df[\"__recency_weight\"].to_numpy().astype(float)\n",
    "\n",
    "    raw_reps = total_items_per_row * rec_weight\n",
    "    capped_reps = np.minimum(np.round(raw_reps), cap).astype(int)\n",
    "    capped_reps = np.maximum(capped_reps, 0) \n",
    "\n",
    "    valid_idx_mask = capped_reps > 0\n",
    "    if not np.any(valid_idx_mask):\n",
    "        return pd.DataFrame(columns=qty_df.columns, dtype=bool)\n",
    "\n",
    "    orig_indices = qty_df.index.to_numpy()[valid_idx_mask]\n",
    "    rep_counts  = capped_reps[valid_idx_mask]\n",
    "    replicated_indices = np.repeat(orig_indices, rep_counts)\n",
    "\n",
    "    if not replicated_indices.size:\n",
    "        return pd.DataFrame(columns=qty_df.columns, dtype=bool)\n",
    "\n",
    "    return qty_df.loc[replicated_indices].gt(0)\n",
    "\n",
    "def _convert_df_to_weighted_coo(\n",
    "    ctx_df: pd.DataFrame,\n",
    "    item_prefix: str,\n",
    "    recency_col_name: str = \"__recency_weight\"\n",
    ") -> tuple[sp.coo_matrix, list[str]]:\n",
    "    all_cols = list(ctx_df.columns)\n",
    "    item_cols = [c for c in all_cols if c.startswith(item_prefix)]\n",
    "    if not item_cols:\n",
    "        return sp.coo_matrix((len(ctx_df), 0), dtype=np.float32), []\n",
    "    \n",
    "    existing_item_cols = [col for col in item_cols if col in ctx_df.columns]\n",
    "    if not existing_item_cols:\n",
    "        return sp.coo_matrix((len(ctx_df),0), dtype=np.float32), []\n",
    "\n",
    "    mat = ctx_df[existing_item_cols].to_numpy(np.float32, copy=False)\n",
    "    \n",
    "    if recency_col_name not in ctx_df.columns:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: '{recency_col_name}' not found for COO weighting. Using uniform weights.\")\n",
    "        rec_weights_np = np.ones(mat.shape[0], dtype=np.float32)\n",
    "    else:\n",
    "        rec_weights_np  = ctx_df[recency_col_name].to_numpy(np.float32)\n",
    "\n",
    "    weighted_mat = mat * rec_weights_np[:, np.newaxis]\n",
    "\n",
    "    r, c = np.nonzero(weighted_mat)\n",
    "    data = weighted_mat[r, c]\n",
    "    coo = sp.coo_matrix((data, (r, c)), shape=(len(ctx_df), len(existing_item_cols)), dtype=np.float32)\n",
    "    return coo, existing_item_cols\n",
    "\n",
    "def compute_cosine_similarity(vector_u: np.ndarray, vector_v: np.ndarray) -> float:\n",
    "    norm_u = np.linalg.norm(vector_u)\n",
    "    norm_v = np.linalg.norm(vector_v)\n",
    "    if norm_u == 0 or norm_v == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(vector_u, vector_v) / (norm_u * norm_v + 1e-12))\n",
    "\n",
    "def ndcg_at_k(recommended_items: list, actual_items_purchased: set, k_val: int) -> float:\n",
    "    if not actual_items_purchased:\n",
    "        return 0.0\n",
    "    effective_k = min(k_val, len(recommended_items))\n",
    "    dcg = 0.0\n",
    "    for i in range(effective_k):\n",
    "        item = recommended_items[i]\n",
    "        if item in actual_items_purchased:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    num_relevant_items_total = len(actual_items_purchased)\n",
    "    idcg = 0.0\n",
    "    for i in range(min(effective_k, num_relevant_items_total)):\n",
    "        idcg += 1.0 / np.log2(i + 2)\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39c9aa-4618-4368-a072-91c894e35f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Association Rule Mining (FP-Growth)\n",
    "\n",
    "def mine_association_rules_for_context(\n",
    "    data_mgr: DataManager,\n",
    "    context_criteria: dict,\n",
    "    rule_p: RuleParams\n",
    "):\n",
    "    cache_differentiating_params = {\n",
    "        \"rlm_s\": rule_p.min_support, \"rlm_c\": rule_p.min_confidence,\n",
    "        \"rlm_l\": rule_p.min_lift, \"rlm_g_len\": rule_p.max_len_global,\n",
    "        \"rlm_s_len\": rule_p.max_itemset_len_segment\n",
    "    }\n",
    "    context_hash_str = ctx_hash(context_criteria, params_for_hash=cache_differentiating_params)\n",
    "    log_context_str = json.dumps(context_criteria) if context_criteria else 'Global (No Context)'\n",
    "    log_context_str += f\" (Recency Weighting: {'On' if RECENCY_WEIGHTING_CONFIG['apply'] else 'Off'})\"\n",
    "\n",
    "    class_rules_pkl_path = MODELS_OUTPUT_DIR / f\"rules_item_class_weighted_{context_hash_str}.pkl\"\n",
    "    segment_rules_pkl_path = MODELS_OUTPUT_DIR / f\"rules_segment_weighted_{context_hash_str}.pkl\"\n",
    "    excel_output_path = MODELS_OUTPUT_DIR / f\"rules_summary_weighted_{context_hash_str}.xlsx\"\n",
    "\n",
    "    if class_rules_pkl_path.exists() and segment_rules_pkl_path.exists():\n",
    "        if VERBOSE_LOGGING: print(f\"â Cache hit for weighted rules ({log_context_str})\")\n",
    "        try:\n",
    "            with open(class_rules_pkl_path, \"rb\") as f1, open(segment_rules_pkl_path, \"rb\") as f2:\n",
    "                return pickle.load(f1), pickle.load(f2)\n",
    "        except Exception as e:\n",
    "            if VERBOSE_LOGGING: print(f\"Warning: Weighted rule cache load failed ({log_context_str}): {e}. Recomputing...\")\n",
    "\n",
    "    if VERBOSE_LOGGING: print(f\"Mining weighted association rules for context: {log_context_str} (params={rule_p})...\")\n",
    "    \n",
    "    training_df = data_mgr.get_dataframe(\"training\")\n",
    "    training_segment_masks = data_mgr.get_segment_masks(\"training\")\n",
    "\n",
    "    try:\n",
    "        context_specific_df = subset_dataframe_by_context(training_df, training_segment_masks, context_criteria)\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Context '{log_context_str}' is invalid for training data masks: {e}\")\n",
    "\n",
    "    empty_rules_df_template = pd.DataFrame(columns=['antecedents','consequents','support','confidence','lift'])\n",
    "    if context_specific_df.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Context '{log_context_str}' (weighted) resulted in zero rows. Caching empty rules.\")\n",
    "        class_rules_pkl_path.write_bytes(pickle.dumps(empty_rules_df_template))\n",
    "        segment_rules_pkl_path.write_bytes(pickle.dumps({}))\n",
    "        return empty_rules_df_template, {}\n",
    "        \n",
    "    boolean_basket_for_context = create_boolean_basket_with_row_replication(\n",
    "        context_specific_df, ITEM_CLASS_PREFIX, cap=MAX_ROW_REP\n",
    "    )\n",
    "    if boolean_basket_for_context.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Weighted boolean basket for context '{log_context_str}' is empty.\")\n",
    "        class_rules_pkl_path.write_bytes(pickle.dumps(empty_rules_df_template))\n",
    "        segment_rules_pkl_path.write_bytes(pickle.dumps({}))\n",
    "        return empty_rules_df_template, {}\n",
    "\n",
    "    fp_kwargs_global = {'min_support': rule_p.min_support, 'use_colnames': True}\n",
    "    if rule_p.max_len_global > 0:\n",
    "        fp_kwargs_global['max_len'] = rule_p.max_len_global\n",
    "    \n",
    "    frequent_itemsets_context_global = fpgrowth(boolean_basket_for_context, **fp_kwargs_global)\n",
    "    \n",
    "    context_global_rules = empty_rules_df_template.copy()\n",
    "    if not frequent_itemsets_context_global.empty:\n",
    "        context_global_rules_temp = association_rules(frequent_itemsets_context_global, metric=\"lift\", min_threshold=rule_p.min_lift)\n",
    "        if not context_global_rules_temp.empty:\n",
    "            context_global_rules = context_global_rules_temp[\n",
    "                context_global_rules_temp['confidence'] >= rule_p.min_confidence\n",
    "            ].reset_index(drop=True)\n",
    "    class_rules_pkl_path.write_bytes(pickle.dumps(context_global_rules))\n",
    "\n",
    "    per_segment_rules_map = {}\n",
    "    fp_kwargs_segment = {'min_support': rule_p.min_support, 'use_colnames': True}\n",
    "    if rule_p.max_itemset_len_segment > 0:\n",
    "        fp_kwargs_segment['max_len'] = rule_p.max_itemset_len_segment\n",
    "\n",
    "    for segment_key_name, original_train_mask in training_segment_masks.items():\n",
    "        df_segment_within_context = context_specific_df[original_train_mask.reindex(context_specific_df.index, fill_value=False)]\n",
    "        if len(df_segment_within_context) < MIN_ROWS_SEG: continue\n",
    "        \n",
    "        basket_for_segment = create_boolean_basket_with_row_replication(df_segment_within_context, ITEM_CLASS_PREFIX, cap=MAX_ROW_REP)\n",
    "        if basket_for_segment.empty or len(basket_for_segment) < MIN_ROWS_SEG: continue\n",
    "            \n",
    "        frequent_itemsets_segment = fpgrowth(basket_for_segment, **fp_kwargs_segment)\n",
    "        if frequent_itemsets_segment.empty: continue\n",
    "\n",
    "        rules_for_segment_df = association_rules(frequent_itemsets_segment, metric=\"confidence\", min_threshold=rule_p.min_confidence)\n",
    "        if not rules_for_segment_df.empty:\n",
    "            rules_for_segment_df = rules_for_segment_df[rules_for_segment_df['lift'] >= rule_p.min_lift]\n",
    "        \n",
    "            if rule_p.max_itemset_len_segment <= 2 and not rules_for_segment_df.empty:\n",
    "                rules_for_segment_df = rules_for_segment_df[\n",
    "                    (rules_for_segment_df[\"antecedents\"].apply(len) == 1) &\n",
    "                    (rules_for_segment_df[\"consequents\"].apply(len) == 1)\n",
    "                ]\n",
    "            if not rules_for_segment_df.empty:\n",
    "                per_segment_rules_map[segment_key_name] = rules_for_segment_df.copy()\n",
    "            \n",
    "    segment_rules_pkl_path.write_bytes(pickle.dumps(per_segment_rules_map))\n",
    "    \n",
    "    if not excel_output_path.exists():\n",
    "        try:\n",
    "            with pd.ExcelWriter(excel_output_path, engine=\"xlsxwriter\") as writer:\n",
    "                def format_rules_for_excel(rules_df_in, class_prefix_to_strip):\n",
    "                    if rules_df_in.empty: return pd.DataFrame(columns=[\"antecedent\", \"consequent\", \"support\", \"confidence\", \"lift\"])\n",
    "                    df = rules_df_in.copy()\n",
    "                    df[\"antecedent\"] = df[\"antecedents\"].apply(lambda s: ', '.join(item.replace(class_prefix_to_strip, \"\") for item in s) if s else None)\n",
    "                    df[\"consequent\"] = df[\"consequents\"].apply(lambda s: ', '.join(item.replace(class_prefix_to_strip, \"\") for item in s) if s else None)\n",
    "                    cols_to_include = [\"antecedent\", \"consequent\", \"support\", \"confidence\", \"lift\"] + [col for col in ['leverage', 'conviction'] if col in df.columns]\n",
    "                    return df[cols_to_include]\n",
    "\n",
    "                formatted_global_rules = format_rules_for_excel(context_global_rules, ITEM_CLASS_PREFIX)\n",
    "                formatted_global_rules.to_excel(writer, sheet_name=\"CONTEXT_GLOBAL_RULES\", index=False)\n",
    "\n",
    "                for seg_name, seg_rules_df_item in per_segment_rules_map.items():\n",
    "                    safe_sheet_name = seg_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\"Â·\", \"-\")[:31]\n",
    "                    formatted_seg_rules = format_rules_for_excel(seg_rules_df_item, ITEM_CLASS_PREFIX)\n",
    "                    formatted_seg_rules.to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "            if VERBOSE_LOGGING: print(f\"â Rules EXPORTED for '{log_context_str}' â {excel_output_path.name}\")\n",
    "        except Exception as e_excel:\n",
    "            if VERBOSE_LOGGING: print(f\"Error during Excel export for {excel_output_path.name}: {e_excel}. Rules remain cached.\")\n",
    "\n",
    "    return context_global_rules, per_segment_rules_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c8283-832c-4829-abba-b9b33d2e323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ALS Model Training\n",
    "\n",
    "def load_context_specific_als_models(data_mgr: DataManager, context_criteria: dict):\n",
    "    context_specific_hash = ctx_hash(context_criteria) \n",
    "    \n",
    "    log_ctx = json.dumps(context_criteria) if context_criteria else 'Global'\n",
    "    log_ctx += f\" (Recency Weighting: {'On' if RECENCY_WEIGHTING_CONFIG['apply'] else 'Off'})\"\n",
    "\n",
    "    cls_model_path = MODELS_OUTPUT_DIR / f\"als_model_item_class_weighted_{context_specific_hash}.npz\"\n",
    "    sku_model_path = MODELS_OUTPUT_DIR / f\"als_model_sku_weighted_{context_specific_hash}.npz\"\n",
    "    meta_path = MODELS_OUTPUT_DIR / f\"als_metadata_weighted_{context_specific_hash}.pkl\"\n",
    "\n",
    "    if cls_model_path.exists() and sku_model_path.exists() and meta_path.exists():\n",
    "        if VERBOSE_LOGGING: print(f\"â Cache hit for weighted ALS models ({log_ctx})\")\n",
    "        try:\n",
    "            class_model = implicit.cpu.als.AlternatingLeastSquares.load(cls_model_path)\n",
    "            sku_model = implicit.cpu.als.AlternatingLeastSquares.load(sku_model_path)\n",
    "            with open(meta_path, \"rb\") as f_meta:\n",
    "                model_metadata = pickle.load(f_meta)\n",
    "            return class_model, sku_model, model_metadata.get(\"item_class_columns\"), model_metadata.get(\"sku_name_columns\")\n",
    "        except Exception as e:\n",
    "            if VERBOSE_LOGGING: print(f\"Warning: Weighted ALS cache load failed ({log_ctx}): {e}. Recomputing...\")\n",
    "\n",
    "    if VERBOSE_LOGGING: print(f\"Training weighted ALS models for context: {log_ctx}...\")\n",
    "    \n",
    "    training_df = data_mgr.get_dataframe(\"training\")\n",
    "    training_segment_masks = data_mgr.get_segment_masks(\"training\")\n",
    "    try:\n",
    "        context_specific_df = subset_dataframe_by_context(training_df, training_segment_masks, context_criteria)\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Context '{log_ctx}' is invalid for training data masks: {e}\")\n",
    "\n",
    "    if context_specific_df.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Context '{log_ctx}' (weighted) produced zero rows. Caching empty ALS.\")\n",
    "        dummy_als_model = implicit.als.AlternatingLeastSquares(factors=1, random_state=42)\n",
    "        empty_cols = []\n",
    "        try: dummy_als_model.save(cls_model_path)\n",
    "        except Exception as e_save:\n",
    "            if VERBOSE_LOGGING: print(f\"Note: Could not save dummy ALS class model: {e_save}\")\n",
    "        try: dummy_als_model.save(sku_model_path)\n",
    "        except Exception as e_save:\n",
    "            if VERBOSE_LOGGING: print(f\"Note: Could not save dummy ALS SKU model: {e_save}\")\n",
    "        \n",
    "        with open(meta_path, \"wb\") as f_meta:\n",
    "            pickle.dump({\"item_class_columns\": empty_cols, \"sku_name_columns\": empty_cols}, f_meta)\n",
    "        return dummy_als_model, dummy_als_model, empty_cols, empty_cols\n",
    "\n",
    "    class_coo_matrix, actual_class_columns = _convert_df_to_weighted_coo(\n",
    "        context_specific_df, ITEM_CLASS_PREFIX, recency_col_name=\"__recency_weight\"\n",
    "    )\n",
    "    class_als_model = implicit.als.AlternatingLeastSquares(factors=60, iterations=20, random_state=42, calculate_training_loss=False)\n",
    "    if class_coo_matrix.shape[1] > 0:\n",
    "        if VERBOSE_LOGGING: print(f\"Fitting weighted ALS Item Class model: {class_coo_matrix.shape[0]} U x {class_coo_matrix.shape[1]} I.\")\n",
    "        class_als_model.fit(class_coo_matrix.tocsr())\n",
    "    try: class_als_model.save(cls_model_path)\n",
    "    except Exception as e:\n",
    "        if VERBOSE_LOGGING: print(f\"Note: Weighted ALS class model save error: {e}\")\n",
    "\n",
    "    sku_coo_matrix, actual_sku_columns = _convert_df_to_weighted_coo(\n",
    "        context_specific_df, SKU_NAME_PREFIX, recency_col_name=\"__recency_weight\"\n",
    "    )\n",
    "    sku_als_model = implicit.als.AlternatingLeastSquares(factors=50, iterations=20, random_state=42, calculate_training_loss=False)\n",
    "    if sku_coo_matrix.shape[1] > 0:\n",
    "        if VERBOSE_LOGGING: print(f\"Fitting weighted ALS SKU model: {sku_coo_matrix.shape[0]} U x {sku_coo_matrix.shape[1]} S.\")\n",
    "        sku_als_model.fit(sku_coo_matrix.tocsr())\n",
    "    try: sku_als_model.save(sku_model_path)\n",
    "    except Exception as e:\n",
    "        if VERBOSE_LOGGING: print(f\"Note: Weighted ALS SKU model save error: {e}\")\n",
    "\n",
    "    with open(meta_path, \"wb\") as f_meta:\n",
    "        pickle.dump({\"item_class_columns\": actual_class_columns, \"sku_name_columns\": actual_sku_columns}, f_meta)\n",
    "    if VERBOSE_LOGGING: print(f\"â Weighted ALS models trained & cached for '{log_ctx}' ({len(actual_class_columns)} C, {len(actual_sku_columns)} S).\")\n",
    "    return class_als_model, sku_als_model, actual_class_columns, actual_sku_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1dd7b-3042-48b1-a8dd-1f64c8446ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Core Recommendation Logic Functions\n",
    "\n",
    "def get_similar_items_from_als_model(\n",
    "    item_id_in_model: int,\n",
    "    als_model: implicit.cpu.als.AlternatingLeastSquares,\n",
    "    num_similar_items: int = 40\n",
    ") -> dict[int, float]:\n",
    "    similar_items_scores = {}\n",
    "    if not (hasattr(als_model, 'item_factors') and als_model.item_factors is not None and\n",
    "            0 < als_model.item_factors.shape[0] and 0 <= item_id_in_model < als_model.item_factors.shape[0]):\n",
    "        return similar_items_scores\n",
    "    for similar_item_idx, score in als_model.similar_items(item_id_in_model, N=num_similar_items + 1):\n",
    "        if int(similar_item_idx) != item_id_in_model:\n",
    "            similar_items_scores[int(similar_item_idx)] = float(score)\n",
    "    return similar_items_scores\n",
    "\n",
    "def compute_als_cosine_with_model_norms(\n",
    "    als_model: implicit.cpu.als.AlternatingLeastSquares,\n",
    "    item_idx_1: int,\n",
    "    item_idx_2: int\n",
    ") -> float:\n",
    "    if not (hasattr(als_model, 'item_factors') and als_model.item_factors is not None and\n",
    "            0 <= item_idx_1 < als_model.item_factors.shape[0] and\n",
    "            0 <= item_idx_2 < als_model.item_factors.shape[0]):\n",
    "        return 0.0\n",
    "    vector_1, vector_2 = als_model.item_factors[item_idx_1], als_model.item_factors[item_idx_2]\n",
    "    if hasattr(als_model, 'item_norms') and als_model.item_norms is not None and \\\n",
    "       item_idx_1 < len(als_model.item_norms) and item_idx_2 < len(als_model.item_norms):\n",
    "        norm_1, norm_2 = als_model.item_norms[item_idx_1], als_model.item_norms[item_idx_2]\n",
    "        return float(np.dot(vector_1, vector_2) / (norm_1 * norm_2 + 1e-12)) if norm_1 * norm_2 > 1e-9 else 0.0\n",
    "    return compute_cosine_similarity(vector_1, vector_2)\n",
    "\n",
    "def get_top_partner_classes(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    context_criteria: dict,\n",
    "    rule_p_for_mining: RuleParams,\n",
    "    num_top_cls: int\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    context_rules_df, _ = mine_association_rules_for_context(data_mgr, context_criteria, rule_p_for_mining)\n",
    "    \n",
    "    target_col_name = ITEM_CLASS_PREFIX + target_item_class_name.upper()\n",
    "\n",
    "    empty_df_out = pd.DataFrame(columns=[\"partner_class_name\", \"support\", \"confidence\", \"lift\", \"als_similarity_score\"])\n",
    "    if context_rules_df.empty or 'antecedents' not in context_rules_df.columns or 'consequents' not in context_rules_df.columns:\n",
    "        return empty_df_out\n",
    "    \n",
    "    target_filter_mask = (\n",
    "        context_rules_df[\"antecedents\"].apply(lambda s: target_col_name in s) |\n",
    "        context_rules_df[\"consequents\"].apply(lambda s: target_col_name in s)\n",
    "    )\n",
    "    relevant_rules = context_rules_df.loc[target_filter_mask, [\"antecedents\", \"consequents\", \"lift\", \"support\", \"confidence\"]].copy()\n",
    "    if relevant_rules.empty: return empty_df_out\n",
    "\n",
    "    def extract_partner_name_from_rule(rule_row_data):\n",
    "        combined_items = set(rule_row_data[\"antecedents\"]).union(set(rule_row_data[\"consequents\"]))\n",
    "        combined_items.discard(target_col_name)\n",
    "        return next(iter(combined_items)).replace(ITEM_CLASS_PREFIX, \"\") if combined_items else None\n",
    "        \n",
    "    relevant_rules[\"partner_class_name\"] = relevant_rules.apply(extract_partner_name_from_rule, axis=1)\n",
    "    relevant_rules.dropna(subset=[\"partner_class_name\"], inplace=True)\n",
    "    if relevant_rules.empty: return empty_df_out\n",
    "\n",
    "    strongest_rules_per_partner = relevant_rules.sort_values(\"lift\", ascending=False).drop_duplicates(\"partner_class_name\", keep=\"first\")\n",
    "    \n",
    "    class_als_model, _, class_model_columns, _ = load_context_specific_als_models(data_mgr, context_criteria)\n",
    "    class_col_to_idx_map = {col: i for i, col in enumerate(class_model_columns)}\n",
    "    \n",
    "    is_als_model_ready = hasattr(class_als_model, 'item_factors') and \\\n",
    "                         class_als_model.item_factors is not None and \\\n",
    "                         class_als_model.item_factors.shape[0] > 0\n",
    "                         \n",
    "    strongest_rules_per_partner[\"als_similarity_score\"] = 0.0 # Initialize\n",
    "    if is_als_model_ready and target_col_name in class_col_to_idx_map:\n",
    "        target_class_model_idx = class_col_to_idx_map[target_col_name]\n",
    "        if 0 <= target_class_model_idx < class_als_model.item_factors.shape[0]:\n",
    "            def calculate_als_similarity_for_partner(partner_class_short_name: str) -> float:\n",
    "                partner_class_col_name = ITEM_CLASS_PREFIX + partner_class_short_name.upper()\n",
    "                if partner_class_col_name not in class_col_to_idx_map: return 0.0\n",
    "                partner_class_model_idx = class_col_to_idx_map[partner_class_col_name]\n",
    "                if not (0 <= partner_class_model_idx < class_als_model.item_factors.shape[0]): return 0.0\n",
    "                return compute_als_cosine_with_model_norms(class_als_model, target_class_model_idx, partner_class_model_idx)\n",
    "            strongest_rules_per_partner[\"als_similarity_score\"] = strongest_rules_per_partner[\"partner_class_name\"].apply(calculate_als_similarity_for_partner)\n",
    "    \n",
    "    final_ranked_classes_df = strongest_rules_per_partner.sort_values(\n",
    "        [\"lift\", \"als_similarity_score\"], ascending=[False, False]\n",
    "    ).head(num_top_cls)\n",
    "    \n",
    "    output_cols = [\"partner_class_name\", \"support\", \"confidence\", \"lift\", \"als_similarity_score\"]\n",
    "    for col in output_cols:\n",
    "        if col not in final_ranked_classes_df.columns:\n",
    "            final_ranked_classes_df[col] = np.nan if col != \"partner_class_name\" else \"N/A_ERROR\"\n",
    "\n",
    "    return final_ranked_classes_df[output_cols].reset_index(drop=True)\n",
    "\n",
    "def get_top_skus_for_partner_class(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    partner_item_class_name: str,\n",
    "    context_criteria: dict,\n",
    "    num_top_skus: int\n",
    ") -> pd.DataFrame: # Changed to return DataFrame\n",
    "    class_to_sku_map_train = data_mgr.cls2sku_train\n",
    "    _, sku_als_model, _, sku_model_cols = load_context_specific_als_models(data_mgr, context_criteria)\n",
    "    sku_col_to_idx_map = {col: i for i, col in enumerate(sku_model_cols)}\n",
    "\n",
    "    target_upper = target_item_class_name.upper()\n",
    "    partner_upper = partner_item_class_name.upper()\n",
    "    target_sku_cols_in_model = [c for c in class_to_sku_map_train.get(target_upper, []) if c in sku_col_to_idx_map]\n",
    "    partner_sku_cols_in_model = [c for c in class_to_sku_map_train.get(partner_upper, []) if c in sku_col_to_idx_map]\n",
    "\n",
    "    empty_df_out = pd.DataFrame(columns=[\"recommended_sku_name\", \"sku_als_similarity\"])\n",
    "    is_sku_als_ready = hasattr(sku_als_model, 'item_factors') and sku_als_model.item_factors is not None and sku_als_model.item_factors.shape[0] > 0\n",
    "    if not (target_sku_cols_in_model and partner_sku_cols_in_model and is_sku_als_ready):\n",
    "        return empty_df_out\n",
    "    \n",
    "    target_sku_factors = [sku_als_model.item_factors[sku_col_to_idx_map[c]] for c in target_sku_cols_in_model if 0 <= sku_col_to_idx_map[c] < sku_als_model.item_factors.shape[0]]\n",
    "    if not target_sku_factors: return empty_df_out\n",
    "    avg_target_sku_vector = np.mean(target_sku_factors, axis=0)\n",
    "    \n",
    "    sku_similarities = []\n",
    "    for partner_sku_col in partner_sku_cols_in_model:\n",
    "        partner_sku_idx = sku_col_to_idx_map[partner_sku_col]\n",
    "        if not (0 <= partner_sku_idx < sku_als_model.item_factors.shape[0]): continue\n",
    "\n",
    "        partner_sku_vector = sku_als_model.item_factors[partner_sku_idx]\n",
    "        similarity = compute_cosine_similarity(avg_target_sku_vector, partner_sku_vector)\n",
    "        sku_short_name = partner_sku_col[len(SKU_NAME_PREFIX):]\n",
    "        sku_similarities.append((sku_short_name, similarity))\n",
    "        \n",
    "    sku_similarities.sort(key=lambda item: item[1], reverse=True)\n",
    "    return pd.DataFrame(sku_similarities[:num_top_skus], columns=[\"recommended_sku_name\", \"sku_als_similarity\"])\n",
    "\n",
    "def generate_recommendations(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    context_criteria: dict | None = None,\n",
    "    rule_p: RuleParams = RuleParams(),\n",
    "    rec_gen_p: RecParams = RecParams()\n",
    "):\n",
    "    effective_context = context_criteria if context_criteria is not None else {}\n",
    "    \n",
    "    partner_classes_df = get_top_partner_classes(\n",
    "        data_mgr, target_item_class_name, effective_context,\n",
    "        rule_p_for_mining=rule_p,\n",
    "        num_top_cls=rec_gen_p.top_classes\n",
    "    )\n",
    "    partner_classes_df = partner_classes_df.rename(columns={\n",
    "        \"partner_class_name\": \"partner_item_class\",\n",
    "        \"als_similarity_score\": \"class_als_similarity\"\n",
    "    })\n",
    "    \n",
    "    sku_recommendations_map = {}\n",
    "    if not partner_classes_df.empty:\n",
    "        for _, row in partner_classes_df.iterrows():\n",
    "            partner_class_name = row[\"partner_item_class\"]\n",
    "            sku_df = get_top_skus_for_partner_class(\n",
    "                data_mgr, target_item_class_name, partner_class_name,\n",
    "                effective_context, rec_gen_p.skus_per_cls\n",
    "            )\n",
    "            sku_recommendations_map[partner_class_name] = sku_df\n",
    "    return partner_classes_df, sku_recommendations_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b56c2-f2bd-41d5-aa2d-1ead969c4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Example generate_recommendations Usage\n",
    "\n",
    "PRIMARY_TARGET_ITEM_DEMO = \"POPCORN\"\n",
    "CTX_ACTION_DEMO = {\"Genre\": \"Action\"}\n",
    "\n",
    "default_rule_params_demo = RuleParams()\n",
    "default_rec_gen_params_demo = RecParams()\n",
    "\n",
    "print(f\"--- Generating recommendations for {PRIMARY_TARGET_ITEM_DEMO} with Context: {CTX_ACTION_DEMO} ---\")\n",
    "partner_classes_df_action, sku_map_action = generate_recommendations(\n",
    "    data_manager_global, PRIMARY_TARGET_ITEM_DEMO, CTX_ACTION_DEMO,\n",
    "    rule_p=default_rule_params_demo, rec_gen_p=default_rec_gen_params_demo\n",
    ")\n",
    "\n",
    "print(f\"\\nRecommended Partner Classes for {PRIMARY_TARGET_ITEM_DEMO} (Action Context) - Recency Weighted:\")\n",
    "if not partner_classes_df_action.empty:\n",
    "    display(partner_classes_df_action)\n",
    "else:\n",
    "    print(f\"No partner classes found for {PRIMARY_TARGET_ITEM_DEMO} in Action context (weighted).\")\n",
    "\n",
    "if sku_map_action:\n",
    "    for partner_name, skus_df_display in sku_map_action.items():\n",
    "        print(f\"\\nâ Top SKUs for Partner Class '{partner_name}' (weighted):\")\n",
    "        if not skus_df_display.empty:\n",
    "            display(skus_df_display)\n",
    "        else:\n",
    "            print(f\"(No specific SKUs recommended for {partner_name} - weighted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a34c54-ec29-4e7b-a2e3-a0ae9ba532a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Example `generate_recommendations` (Kids G & English Noon Contexts)\n",
    "\n",
    "CTX_KIDS_G_DEMO = {\"Rating\": \"G\"}\n",
    "CTX_ENGLISH_NOON_DEMO = {\"Language\":\"English\", \"Slot\":\"Noon\"}\n",
    "\n",
    "if 'PRIMARY_TARGET_ITEM_DEMO' not in locals(): PRIMARY_TARGET_ITEM_DEMO = \"POPCORN\"\n",
    "if 'default_rule_params_demo' not in locals(): default_rule_params_demo = RuleParams()\n",
    "if 'default_rec_gen_params_demo' not in locals(): default_rec_gen_params_demo = RecParams()\n",
    "\n",
    "\n",
    "print(f\"\\n--- Recommendations for {PRIMARY_TARGET_ITEM_DEMO} (Context: {CTX_KIDS_G_DEMO}) ---\")\n",
    "p_cls_kids_g, s_map_kids_g = generate_recommendations(\n",
    "    data_manager_global, PRIMARY_TARGET_ITEM_DEMO, CTX_KIDS_G_DEMO,\n",
    "    default_rule_params_demo, default_rec_gen_params_demo\n",
    ")\n",
    "print(f\"Partner Classes ({CTX_KIDS_G_DEMO}):\")\n",
    "if not p_cls_kids_g.empty: display(p_cls_kids_g)\n",
    "else: print(\"None\")\n",
    "if s_map_kids_g:\n",
    "    for partner, df_skus in s_map_kids_g.items():\n",
    "        print(f\"\\nâ Top SKUs for Partner '{partner}':\")\n",
    "        display(df_skus) if not df_skus.empty else print(f\"(No SKUs for {partner})\")\n",
    "\n",
    "print(f\"\\n--- Recommendations for {PRIMARY_TARGET_ITEM_DEMO} (Context: {CTX_ENGLISH_NOON_DEMO}) ---\")\n",
    "p_cls_en, s_map_en = generate_recommendations(\n",
    "    data_manager_global, PRIMARY_TARGET_ITEM_DEMO, CTX_ENGLISH_NOON_DEMO,\n",
    "    default_rule_params_demo, default_rec_gen_params_demo\n",
    ")\n",
    "print(f\"Partner Classes ({CTX_ENGLISH_NOON_DEMO}):\")\n",
    "if not p_cls_en.empty: display(p_cls_en)\n",
    "else: print(\"None\")\n",
    "if s_map_en:\n",
    "    for partner, df_skus in s_map_en.items():\n",
    "        print(f\"\\nâ Top SKUs for Partner '{partner}':\")\n",
    "        display(df_skus) if not df_skus.empty else print(f\"(No SKUs for {partner})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c7ca8-4c35-426e-b405-a07d8546cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Export Recommendations to Excel\n",
    "\n",
    "def export_recommendations_to_excel(\n",
    "    data_mgr: DataManager, target_item_class_name: str, context_criteria: dict,\n",
    "    rule_p: RuleParams = RuleParams(), \n",
    "    rec_gen_p: RecParams = RecParams(), \n",
    "    output_excel_path: str | Path | None = None\n",
    "):\n",
    "    log_ctx = json.dumps(context_criteria) if context_criteria else 'Global'\n",
    "    log_ctx += f\" (Recency Weighting: {'On' if RECENCY_WEIGHTING_CONFIG['apply'] else 'Off'})\"\n",
    "    if VERBOSE_LOGGING: print(f\"Exporting recommendations for '{target_item_class_name}' in context: {log_ctx}\")\n",
    "\n",
    "    if output_excel_path is None:\n",
    "        tag_parts = []\n",
    "        for k, v_list_item in sorted(context_criteria.items()): # Use different var name\n",
    "            vals_str = \"_\".join(sorted(v_list_item)) if isinstance(v_list_item, list) else str(v_list_item)\n",
    "            tag_parts.append(f\"{k}-{vals_str}\")\n",
    "        tag = \"_\".join(tag_parts) if context_criteria else \"ALL\"\n",
    "        tag = tag.replace(\" \", \"\").replace(\"Â·\", \"-\").replace(\"\\\"\", \"\").replace(\"'\", \"\") # Further sanitize\n",
    "        \n",
    "        stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_path = MODELS_OUTPUT_DIR / f\"recs_{target_item_class_name}_{tag}_{stamp}.xlsx\"\n",
    "    else:\n",
    "        final_path = Path(output_excel_path)\n",
    "    final_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    partner_classes_df, sku_map = generate_recommendations(\n",
    "        data_mgr, target_item_class_name, context_criteria, rule_p, rec_gen_p\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(final_path, engine=\"xlsxwriter\") as writer:\n",
    "        # Ensure column names in partner_classes_df match these expected names\n",
    "        # generate_recommendations already renames them to partner_item_class and class_als_similarity\n",
    "        expected_partner_cols = [\"partner_item_class\", \"support\", \"confidence\", \"lift\", \"class_als_similarity\"]\n",
    "        \n",
    "        if not partner_classes_df.empty:\n",
    "            df_to_export_partners = pd.DataFrame(columns=expected_partner_cols)\n",
    "            for col_name in expected_partner_cols:\n",
    "                if col_name in partner_classes_df.columns:\n",
    "                    df_to_export_partners[col_name] = partner_classes_df[col_name]\n",
    "                else:\n",
    "                    df_to_export_partners[col_name] = np.nan\n",
    "            df_to_export_partners.to_excel(writer, sheet_name=\"TOP_PARTNER_CLASSES\", index=False)\n",
    "        else:\n",
    "            pd.DataFrame({\"info\": [f\"No partner classes for {target_item_class_name} in {log_ctx}\"]}).to_excel(writer, sheet_name=\"TOP_PARTNER_CLASSES\", index=False)\n",
    "\n",
    "        if sku_map:\n",
    "            for partner_name, skus_df_to_export in sku_map.items():\n",
    "                safe_sheet_name = str(partner_name).replace(\"/\", \"_\").replace(\" \", \"_\").replace(\"Â·\", \"-\")[:31]\n",
    "                if skus_df_to_export.empty:\n",
    "                    pd.DataFrame({\"info\": [f\"(No SKUs for {partner_name} in this context)\"]}).to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "                else:\n",
    "                    skus_df_to_export.to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "        else:\n",
    "            pd.DataFrame({\"info\": [\"No SKU map generated.\"]}).to_excel(writer, sheet_name=\"SKU_INFO\", index=False)\n",
    "\n",
    "    print(f\"â Recommendations for '{target_item_class_name}' (context: {log_ctx}) saved to Excel: {final_path}\")\n",
    "\n",
    "if 'CTX_ACTION_DEMO' in locals() and 'PRIMARY_TARGET_ITEM_DEMO' in locals() and \\\n",
    "   'default_rule_params_demo' in locals() and 'default_rec_gen_params_demo' in locals():\n",
    "    export_recommendations_to_excel(\n",
    "        data_manager_global, PRIMARY_TARGET_ITEM_DEMO, CTX_ACTION_DEMO,\n",
    "        default_rule_params_demo, default_rec_gen_params_demo,\n",
    "        MODELS_OUTPUT_DIR / f\"exported_recs_{PRIMARY_TARGET_ITEM_DEMO.lower()}_action_{CACHE_VERSION_PREFIX.strip('_')}.xlsx\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da56a1-8336-4783-b152-34a615f29ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Multi-Metric Evaluation Function\n",
    "\n",
    "def evaluate_recommendations_on_holdout_multi_metric(\n",
    "    data_mgr: DataManager, target_item_class_name: str, context_criteria: dict,\n",
    "    rule_p: RuleParams = RuleParams(), \n",
    "    rec_gen_p: RecParams = RecParams(), \n",
    "    eval_k_p: EvaluationKValueParam = EvaluationKValueParam()\n",
    ") -> dict:\n",
    "    log_ctx = json.dumps(context_criteria) if context_criteria else 'Global'\n",
    "    log_ctx_print = log_ctx + f\" (Recency Weighting: {'On' if RECENCY_WEIGHTING_CONFIG['apply'] else 'Off'})\"\n",
    "\n",
    "    if VERBOSE_LOGGING: print(f\"\\n--- Evaluating (Multi-Metric) holdout: {log_ctx_print}, target: {target_item_class_name} ---\")\n",
    "\n",
    "    partner_classes_df, sku_recommendations_map = generate_recommendations(\n",
    "        data_mgr, target_item_class_name, context_criteria, rule_p, rec_gen_p\n",
    "    )\n",
    "\n",
    "    all_recommended_skus_ordered_list = []\n",
    "    temp_sku_set_for_ordering = set()\n",
    "    if sku_recommendations_map:\n",
    "        ordered_partners = []\n",
    "        if not partner_classes_df.empty and \"partner_item_class\" in partner_classes_df.columns: # Adjusted column name\n",
    "             ordered_partners = partner_classes_df[\"partner_item_class\"].tolist()\n",
    "        else: \n",
    "             ordered_partners = list(sku_recommendations_map.keys())\n",
    "\n",
    "        for partner_name in ordered_partners:\n",
    "            if partner_name not in sku_recommendations_map: continue\n",
    "            skus_df = sku_recommendations_map[partner_name]\n",
    "            if \"recommended_sku_name\" in skus_df.columns and not skus_df.empty:\n",
    "                 for sku_item in skus_df.recommended_sku_name.tolist():\n",
    "                    if sku_item not in temp_sku_set_for_ordering:\n",
    "                        all_recommended_skus_ordered_list.append(sku_item)\n",
    "                        temp_sku_set_for_ordering.add(sku_item)\n",
    "\n",
    "    all_recommended_skus_set = set(all_recommended_skus_ordered_list)\n",
    "    effective_k_for_evaluation = min(eval_k_p.k_for_rank_metrics, len(all_recommended_skus_ordered_list))\n",
    "\n",
    "    default_metrics_dict = {\"hit_rate\": 0.0, \"precision_at_k\": 0.0, \"recall_at_k\": 0.0,\n",
    "                            \"ndcg_at_k\": 0.0, \"evaluated_sessions\": 0, \"k_value\": effective_k_for_evaluation}\n",
    "\n",
    "    if effective_k_for_evaluation == 0 and len(all_recommended_skus_ordered_list) > 0 :\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: k_for_eval_metrics is 0 for context '{log_ctx_print}'. P,R,NDCG metrics will be 0.\")\n",
    "    elif not all_recommended_skus_set:\n",
    "        if VERBOSE_LOGGING: print(f\"No SKUs recommended for target '{target_item_class_name}' in context '{log_ctx_print}'.\")\n",
    "        return {**default_metrics_dict, \"error\": \"No SKUs recommended\"}\n",
    "\n",
    "    holdout_df = data_mgr.get_dataframe(\"holdout\")\n",
    "    holdout_masks = data_mgr.get_segment_masks(\"holdout\")\n",
    "    try:\n",
    "        holdout_df_context_specific = subset_dataframe_by_context(holdout_df, holdout_masks, context_criteria)\n",
    "    except KeyError as e:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Context '{log_ctx_print}' invalid for holdout data: {e}.\")\n",
    "        return {**default_metrics_dict, \"error\": f\"Context invalid for holdout: {e}\"}\n",
    "    if holdout_df_context_specific.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Context '{log_ctx_print}' resulted in an empty slice in holdout data.\")\n",
    "        return {**default_metrics_dict, \"error\": \"Empty holdout slice\"}\n",
    "\n",
    "    target_col = ITEM_CLASS_PREFIX + target_item_class_name.upper()\n",
    "    if target_col not in holdout_df_context_specific.columns:\n",
    "        if VERBOSE_LOGGING: print(f\"Warning: Target class '{target_col}' not in holdout slice for '{log_ctx_print}'.\")\n",
    "        return {**default_metrics_dict, \"error\": \"Target column missing in holdout\"}\n",
    "\n",
    "    sessions_with_target = holdout_df_context_specific[holdout_df_context_specific[target_col] > 0]\n",
    "    if sessions_with_target.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"No sessions in holdout (context: '{log_ctx_print}') where target '{target_item_class_name}' was purchased.\")\n",
    "        return {**default_metrics_dict, \"hit_rate\": np.nan, \"precision_at_k\": np.nan, \"recall_at_k\": np.nan, \"ndcg_at_k\": np.nan, \"error\": \"No relevant sessions in holdout\"}\n",
    "\n",
    "    num_evaluated_sessions = 0; total_hits = 0; precision_sum = 0.0; recall_sum = 0.0; ndcg_sum = 0.0\n",
    "    sku_name_prefix_len = len(SKU_NAME_PREFIX)\n",
    "\n",
    "    progress_bar_description = f\"Scoring Holdout ({log_ctx[:25]})\"\n",
    "    for _, session_data_row in tqdm(sessions_with_target.iterrows(), total=len(sessions_with_target), desc=progress_bar_description, leave=False):\n",
    "        purchased_skus_in_this_session_set = {\n",
    "            col_name[sku_name_prefix_len:]\n",
    "            for col_name, quantity in session_data_row.items()\n",
    "            if isinstance(col_name, str) and col_name.startswith(SKU_NAME_PREFIX) and quantity > 0\n",
    "        }\n",
    "        if not purchased_skus_in_this_session_set: continue\n",
    "\n",
    "        num_evaluated_sessions += 1\n",
    "        if all_recommended_skus_set.intersection(purchased_skus_in_this_session_set):\n",
    "            total_hits += 1\n",
    "\n",
    "        if effective_k_for_evaluation > 0:\n",
    "            top_k_recs_for_this_evaluation = all_recommended_skus_ordered_list[:effective_k_for_evaluation]\n",
    "            relevant_recommended_in_top_k = set(top_k_recs_for_this_evaluation).intersection(purchased_skus_in_this_session_set)\n",
    "\n",
    "            precision_sum += len(relevant_recommended_in_top_k) / effective_k_for_evaluation\n",
    "            if purchased_skus_in_this_session_set:\n",
    "                recall_sum += len(relevant_recommended_in_top_k) / len(purchased_skus_in_this_session_set)\n",
    "            ndcg_sum += ndcg_at_k(top_k_recs_for_this_evaluation, purchased_skus_in_this_session_set, effective_k_for_evaluation)\n",
    "\n",
    "    final_metrics_results = {\"evaluated_sessions\": num_evaluated_sessions, \"k_value\": effective_k_for_evaluation}\n",
    "    if num_evaluated_sessions > 0:\n",
    "        final_metrics_results[\"hit_rate\"] = total_hits / num_evaluated_sessions\n",
    "        if effective_k_for_evaluation > 0:\n",
    "            final_metrics_results[\"precision_at_k\"] = precision_sum / num_evaluated_sessions\n",
    "            final_metrics_results[\"recall_at_k\"] = recall_sum / num_evaluated_sessions\n",
    "            final_metrics_results[\"ndcg_at_k\"] = ndcg_sum / num_evaluated_sessions\n",
    "        else:\n",
    "            final_metrics_results.update({\"precision_at_k\": 0.0, \"recall_at_k\": 0.0, \"ndcg_at_k\": 0.0})\n",
    "    else:\n",
    "        final_metrics_results.update(default_metrics_dict)\n",
    "        final_metrics_results[\"hit_rate\"] = np.nan\n",
    "        final_metrics_results[\"precision_at_k\"] = np.nan\n",
    "        final_metrics_results[\"recall_at_k\"] = np.nan\n",
    "        final_metrics_results[\"ndcg_at_k\"] = np.nan\n",
    "\n",
    "    print(f\"Holdout Metrics for '{log_ctx_print}' (k_eval={effective_k_for_evaluation}, {num_evaluated_sessions} sessions):\")\n",
    "    for metric_name, metric_value in final_metrics_results.items():\n",
    "        if metric_name not in [\"evaluated_sessions\", \"k_value\", \"error\"]:\n",
    "            formatted_metric_name = metric_name.replace('_at_k', f'@{effective_k_for_evaluation}').replace('_', ' ').title()\n",
    "            print(f\"  {formatted_metric_name}: {metric_value:.4f}\" if isinstance(metric_value, float) else f\"  {metric_name}: {metric_value}\")\n",
    "\n",
    "    return final_metrics_results\n",
    "\n",
    "if 'CTX_ACTION_DEMO' in locals() and 'PRIMARY_TARGET_ITEM_DEMO' in locals() and \\\n",
    "   'default_rule_params_demo' in locals() and 'default_rec_gen_params_demo' in locals():\n",
    "    print(f\"\\n--- Evaluating Target '{PRIMARY_TARGET_ITEM_DEMO}' (Action Context) with Multiple Metrics ---\")\n",
    "    action_eval_metrics = evaluate_recommendations_on_holdout_multi_metric(\n",
    "        data_manager_global, PRIMARY_TARGET_ITEM_DEMO, CTX_ACTION_DEMO,\n",
    "        default_rule_params_demo, default_rec_gen_params_demo,\n",
    "        EvaluationKValueParam(k_for_rank_metrics=5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769da7a3-9f06-4f34-b576-f0d0dacff154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: EDA for a specific TARGET_ITEM (Parameterized)\n",
    "\n",
    "def get_top_copurchased_classes(df_slice, target_col, class_prefix):\n",
    "    if df_slice.empty or target_col not in df_slice.columns:\n",
    "        return pd.Series(dtype=int, name=\"Co-purchased Class Counts\")\n",
    "    sessions_with_target_item = df_slice[df_slice[target_col].gt(0)]\n",
    "    if sessions_with_target_item.empty:\n",
    "        return pd.Series(dtype=int, name=\"Co-purchased Class Counts\")\n",
    "    copurchased_counts = (sessions_with_target_item.filter(like=class_prefix)\n",
    "                                                 .gt(0).sum()\n",
    "                                                 .sort_values(ascending=False))\n",
    "    return copurchased_counts.drop(labels=target_col, errors='ignore')\n",
    "\n",
    "def top_skus_in_class_for_slice(\n",
    "    df_slice_to_analyze: pd.DataFrame,\n",
    "    item_class_short_name: str,\n",
    "    class_to_sku_column_map: dict,\n",
    "    sku_column_prefix_to_strip: str,\n",
    "    num_top_skus: int = 10\n",
    ") -> pd.Series:\n",
    "    sku_columns_for_the_class = class_to_sku_column_map.get(item_class_short_name.upper(), [])\n",
    "\n",
    "    if not sku_columns_for_the_class or df_slice_to_analyze.empty:\n",
    "        return pd.Series([], dtype=int, name=\"SKU Purchase Counts\")\n",
    "\n",
    "    valid_sku_columns_in_slice = [\n",
    "        col for col in sku_columns_for_the_class if col in df_slice_to_analyze.columns\n",
    "    ]\n",
    "    if not valid_sku_columns_in_slice:\n",
    "        return pd.Series([], dtype=int, name=\"SKU Purchase Counts\")\n",
    "\n",
    "    sku_purchase_counts = (\n",
    "        df_slice_to_analyze[valid_sku_columns_in_slice].gt(0).sum()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "\n",
    "    top_n_skus_series = sku_purchase_counts.head(num_top_skus).rename(\n",
    "        index=lambda col_name: col_name[len(sku_column_prefix_to_strip):]\n",
    "    )\n",
    "    return top_n_skus_series\n",
    "\n",
    "TARGET_ITEM_FOR_EDA = \"DRINKS\"\n",
    "print(f\"\\n--- EDA: Analyzing Training Data Slices for Target: {TARGET_ITEM_FOR_EDA} ---\")\n",
    "\n",
    "training_df_full_eda = data_manager_global.get_dataframe(\"training\") \n",
    "training_segment_masks_eda = data_manager_global.get_segment_masks(\"training\")\n",
    "class_to_sku_map_training_data_eda = data_manager_global.cls2sku_train\n",
    "target_col_name_eda = ITEM_CLASS_PREFIX + TARGET_ITEM_FOR_EDA.upper()\n",
    "\n",
    "if target_col_name_eda not in training_df_full_eda.columns:\n",
    "    print(f\"Error: Target column '{target_col_name_eda}' not found. EDA for {TARGET_ITEM_FOR_EDA} cannot proceed.\")\n",
    "else:\n",
    "    target_purchase_mask_training_eda = training_df_full_eda[target_col_name_eda].gt(0)\n",
    "    print(f\"\\n--- {TARGET_ITEM_FOR_EDA} Purchase Statistics (Training Data - Recency Weighted Influence on Counts if used in df_slice) ---\")\n",
    "    print(f\"Total sessions with {TARGET_ITEM_FOR_EDA} (in full data): {target_purchase_mask_training_eda.sum()}\")\n",
    "\n",
    "    if 'CTX_ACTION_DEMO' not in locals(): CTX_ACTION_DEMO = {\"Genre\": \"Action\"}\n",
    "    if 'CTX_KIDS_G_DEMO' not in locals(): CTX_KIDS_G_DEMO = {\"Rating\": \"G\"}\n",
    "    if 'CTX_ENGLISH_NOON_DEMO' not in locals(): CTX_ENGLISH_NOON_DEMO = {\"Language\":\"English\", \"Slot\":\"Noon\"}\n",
    "\n",
    "    contexts_for_this_eda = {\n",
    "        \"Action\": CTX_ACTION_DEMO,\n",
    "        \"Kids_G_Rating\": CTX_KIDS_G_DEMO,\n",
    "        \"English_Noon_Slot\": CTX_ENGLISH_NOON_DEMO\n",
    "    }\n",
    "\n",
    "    for ctx_name, ctx_dict_eda_item in contexts_for_this_eda.items():\n",
    "        if ctx_dict_eda_item is None:\n",
    "            if VERBOSE_LOGGING: print(f\"Skipping EDA for {ctx_name} (context variable not defined).\")\n",
    "            continue\n",
    "        try:\n",
    "            df_slice_eda_item = subset_dataframe_by_context(training_df_full_eda, training_segment_masks_eda, ctx_dict_eda_item)\n",
    "            if df_slice_eda_item.empty or target_col_name_eda not in df_slice_eda_item.columns:\n",
    "                if VERBOSE_LOGGING: print(f\"Slice for '{ctx_name}' empty or target '{TARGET_ITEM_FOR_EDA}' missing during EDA.\")\n",
    "                continue\n",
    "\n",
    "            num_target_in_slice_item = (df_slice_eda_item[target_col_name_eda].gt(0)).sum()\n",
    "            print(f\"\\nSessions with {TARGET_ITEM_FOR_EDA} in '{ctx_name}' context ({json.dumps(ctx_dict_eda_item)}): {num_target_in_slice_item}\")\n",
    "\n",
    "            if num_target_in_slice_item > 0:\n",
    "                top_copurchased_classes_eda_item = get_top_copurchased_classes(df_slice_eda_item, target_col_name_eda, ITEM_CLASS_PREFIX)\n",
    "                if not top_copurchased_classes_eda_item.empty:\n",
    "                    print(f\"  Top co-purchased classes with {TARGET_ITEM_FOR_EDA} in '{ctx_name}':\")\n",
    "                    display(top_copurchased_classes_eda_item.head(3))\n",
    "\n",
    "                    df_slice_with_target_for_skus_item = df_slice_eda_item[df_slice_eda_item[target_col_name_eda].gt(0)]\n",
    "                    top_partner_names_eda_item = [\n",
    "                        c[len(ITEM_CLASS_PREFIX):] for c in top_copurchased_classes_eda_item.head(2).index\n",
    "                    ]\n",
    "                    for partner_cls_name_eda_item in top_partner_names_eda_item:\n",
    "                        print(f\"    Top SKUs in '{partner_cls_name_eda_item}' (co-purchased with {TARGET_ITEM_FOR_EDA} in {ctx_name}):\")\n",
    "                        skus_df_eda_item = top_skus_in_class_for_slice(\n",
    "                            df_slice_with_target_for_skus_item,\n",
    "                            partner_cls_name_eda_item,\n",
    "                            class_to_sku_map_training_data_eda,\n",
    "                            SKU_NAME_PREFIX,\n",
    "                            num_top_skus=3\n",
    "                        )\n",
    "                        display(skus_df_eda_item) if not skus_df_eda_item.empty else print(\"    (No SKUs found or displayable)\")\n",
    "        except KeyError as e:\n",
    "            if VERBOSE_LOGGING: print(f\"EDA slice error for '{ctx_name}' with target {TARGET_ITEM_FOR_EDA}: {e}\")\n",
    "            print(f\"Could not process EDA for '{ctx_name}' due to context key issue: {e}. Please check context definitions and available masks.\")\n",
    "        except Exception as e_gen:\n",
    "             if VERBOSE_LOGGING: print(f\"General error during EDA for '{ctx_name}' with target {TARGET_ITEM_FOR_EDA}: {e_gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c65ed9-64ca-4642-9c5d-8014fc531f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Personalized SKU Ranking (Function and Demo)\n",
    "\n",
    "def get_personalized_sku_ranking(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    partner_item_class_name: str,\n",
    "    context_criteria: dict,\n",
    "    df_slice_for_frequency: pd.DataFrame,\n",
    "    blending_alpha: float = 0.5,\n",
    "    num_top_skus: int = 10\n",
    ") -> pd.DataFrame:\n",
    "    class_to_sku_col_map_training = data_mgr.cls2sku_train\n",
    "    partner_class_name_upper = partner_item_class_name.upper()\n",
    "\n",
    "    sku_cols_for_partner_in_freq_slice = [\n",
    "        col for col in class_to_sku_col_map_training.get(partner_class_name_upper, [])\n",
    "        if col in df_slice_for_frequency.columns\n",
    "    ]\n",
    "\n",
    "    normalized_sku_frequency = pd.Series(dtype=float, name=\"normalized_frequency\")\n",
    "    if not df_slice_for_frequency.empty and sku_cols_for_partner_in_freq_slice:\n",
    "        raw_sku_purchase_counts = df_slice_for_frequency[sku_cols_for_partner_in_freq_slice].gt(0).sum()\n",
    "        if not raw_sku_purchase_counts.empty:\n",
    "            raw_sku_purchase_counts.rename(index=lambda col_name: col_name[len(SKU_NAME_PREFIX):], inplace=True)\n",
    "            if raw_sku_purchase_counts.max() > 0:\n",
    "                normalized_sku_frequency = raw_sku_purchase_counts / raw_sku_purchase_counts.max()\n",
    "            else:\n",
    "                normalized_sku_frequency = pd.Series(0.0, index=raw_sku_purchase_counts.index)\n",
    "            normalized_sku_frequency.name = \"normalized_frequency\"\n",
    "\n",
    "    als_similarity_df_from_func = get_top_skus_for_partner_class( # This now returns a DataFrame\n",
    "        data_mgr, target_item_class_name, partner_item_class_name, context_criteria, # Pass data_mgr\n",
    "        num_top_skus=max(num_top_skus * 3, 30) \n",
    "    )\n",
    "    als_similarity_df = pd.DataFrame()\n",
    "    if not als_similarity_df_from_func.empty and \"recommended_sku_name\" in als_similarity_df_from_func.columns:\n",
    "        als_similarity_df = als_similarity_df_from_func.rename(\n",
    "            columns={\"recommended_sku_name\": \"short_sku_name\", \"sku_als_similarity\": \"als_similarity_score\"}\n",
    "        ).set_index('short_sku_name')\n",
    "\n",
    "    all_partner_skus_short_names_from_map = [\n",
    "        col[len(SKU_NAME_PREFIX):]\n",
    "        for col in class_to_sku_col_map_training.get(partner_class_name_upper, [])\n",
    "    ]\n",
    "    if not all_partner_skus_short_names_from_map:\n",
    "        return pd.DataFrame(columns=['short_sku_name', 'hybrid_score', 'normalized_frequency', 'als_similarity_score'])\n",
    "\n",
    "    unique_partner_skus_index = pd.Index(list(set(all_partner_skus_short_names_from_map)), name='short_sku_name')\n",
    "    combined_scores_df = pd.DataFrame(index=unique_partner_skus_index)\n",
    "\n",
    "    combined_scores_df = combined_scores_df.join(\n",
    "        normalized_sku_frequency, how='left'\n",
    "    ).fillna({'normalized_frequency': 0.0})\n",
    "\n",
    "    if not als_similarity_df.empty:\n",
    "        combined_scores_df = combined_scores_df.join(\n",
    "            als_similarity_df['als_similarity_score'], how='left'\n",
    "        ).fillna({'als_similarity_score': 0.0})\n",
    "    else:\n",
    "        combined_scores_df['als_similarity_score'] = 0.0\n",
    "\n",
    "    combined_scores_df['hybrid_score'] = (\n",
    "        blending_alpha * combined_scores_df['normalized_frequency'] +\n",
    "        (1 - blending_alpha) * combined_scores_df['als_similarity_score']\n",
    "    )\n",
    "\n",
    "    final_ranked_skus_df = (\n",
    "        combined_scores_df.sort_values('hybrid_score', ascending=False)\n",
    "        .head(num_top_skus)\n",
    "        [['hybrid_score', 'normalized_frequency', 'als_similarity_score']]\n",
    "        .reset_index()\n",
    "    )\n",
    "    return final_ranked_skus_df\n",
    "\n",
    "if 'PRIMARY_TARGET_ITEM_DEMO' in locals() and \\\n",
    "   'CTX_KIDS_G_DEMO' in locals() and CTX_KIDS_G_DEMO is not None and \\\n",
    "   'training_df_full_eda' in locals() and not training_df_full_eda.empty:\n",
    "\n",
    "    print(f\"\\n--- Personalized SKU Ranking Demo ---\")\n",
    "    print(f\"Target: {PRIMARY_TARGET_ITEM_DEMO}, Partner: DRINKS, Context: Kids G ({json.dumps(CTX_KIDS_G_DEMO)})\")\n",
    "\n",
    "    df_kids_g_slice_for_freq_calc_demo = pd.DataFrame()\n",
    "    try:\n",
    "        df_kids_g_slice_for_freq_calc_demo = subset_dataframe_by_context(\n",
    "            training_df_full_eda,\n",
    "            data_manager_global.get_segment_masks(\"training\"),\n",
    "            CTX_KIDS_G_DEMO\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not create Kids G slice for frequency calculation: {e}\")\n",
    "\n",
    "    if not df_kids_g_slice_for_freq_calc_demo.empty:\n",
    "        target_col_for_freq_demo = ITEM_CLASS_PREFIX + PRIMARY_TARGET_ITEM_DEMO.upper()\n",
    "        if target_col_for_freq_demo in df_kids_g_slice_for_freq_calc_demo.columns:\n",
    "            df_target_in_kids_g_for_freq_demo = df_kids_g_slice_for_freq_calc_demo[\n",
    "                df_kids_g_slice_for_freq_calc_demo[target_col_for_freq_demo].gt(0)\n",
    "            ]\n",
    "            if not df_target_in_kids_g_for_freq_demo.empty:\n",
    "                personalized_skus_df_kids_demo = get_personalized_sku_ranking(\n",
    "                    data_manager_global,\n",
    "                    PRIMARY_TARGET_ITEM_DEMO,\n",
    "                    \"DRINKS\",\n",
    "                    CTX_KIDS_G_DEMO,\n",
    "                    df_target_in_kids_g_for_freq_demo,\n",
    "                    blending_alpha=0.6,\n",
    "                    num_top_skus=3\n",
    "                )\n",
    "                if not personalized_skus_df_kids_demo.empty:\n",
    "                    display(personalized_skus_df_kids_demo)\n",
    "                else:\n",
    "                    print(f\"No personalized SKU ranking for DRINKS (Target: {PRIMARY_TARGET_ITEM_DEMO}, Context: Kids G).\")\n",
    "            else:\n",
    "                print(f\"No sessions in Kids G slice where {PRIMARY_TARGET_ITEM_DEMO} was purchased.\")\n",
    "        else:\n",
    "            print(f\"Target column '{target_col_for_freq_demo}' not in Kids G EDA slice.\")\n",
    "    else:\n",
    "        print(\"Skipping personalized ranking demo: Kids G slice for frequency is empty.\")\n",
    "else:\n",
    "    print(\"Skipping personalized_sku_ranking demo: Required variables not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92dd6c1-9455-4a49-b5d9-5b95f0896b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Comparison of Holdout Performance (Multi-Metric Table)\n",
    "\n",
    "def compare_holdout_performance_across_slices_multi_metric(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    list_of_context_criteria: list[dict],\n",
    "    rule_p: RuleParams = RuleParams(),\n",
    "    rec_gen_p: RecParams = RecParams(),\n",
    "    eval_k_p: EvaluationKValueParam = EvaluationKValueParam()\n",
    ") -> pd.DataFrame:\n",
    "    performance_records = []\n",
    "\n",
    "    holdout_df_full = data_mgr.get_dataframe(\"holdout\")\n",
    "    holdout_segment_masks = data_mgr.get_segment_masks(\"holdout\")\n",
    "    target_item_class_col_name = ITEM_CLASS_PREFIX + target_item_class_name.upper()\n",
    "\n",
    "    for context_dict_item in list_of_context_criteria:\n",
    "        context_description_str = json.dumps(context_dict_item) if context_dict_item else \"Global (No Context)\"\n",
    "\n",
    "        eval_metrics_dict = evaluate_recommendations_on_holdout_multi_metric(\n",
    "            data_mgr, target_item_class_name, context_dict_item,\n",
    "            rule_p, rec_gen_p, eval_k_p\n",
    "        )\n",
    "\n",
    "        num_sessions_with_target_in_holdout_slice = 0\n",
    "        try:\n",
    "            holdout_df_context_specific = subset_dataframe_by_context(\n",
    "                holdout_df_full, holdout_segment_masks, context_dict_item\n",
    "            )\n",
    "            if not holdout_df_context_specific.empty and target_item_class_col_name in holdout_df_context_specific.columns:\n",
    "                num_sessions_with_target_in_holdout_slice = int(\n",
    "                    holdout_df_context_specific[target_item_class_col_name].gt(0).sum()\n",
    "                )\n",
    "            elif not holdout_df_context_specific.empty and target_item_class_col_name not in holdout_df_context_specific.columns:\n",
    "                if VERBOSE_LOGGING: print(f\"Info (for table): Target col '{target_item_class_col_name}' missing in holdout slice for '{context_description_str}'.\")\n",
    "        except KeyError as e:\n",
    "            if VERBOSE_LOGGING: print(f\"Info (for table): Context '{context_description_str}' not fully applicable to holdout: {e}\")\n",
    "\n",
    "        record = {\n",
    "            \"context_description\": context_description_str,\n",
    "            \"target_item_sessions_in_holdout_slice\": num_sessions_with_target_in_holdout_slice,\n",
    "            \"k_for_metrics_calc\": eval_metrics_dict.get(\"k_value\", eval_k_p.k_for_rank_metrics),\n",
    "            \"hit_rate\": eval_metrics_dict.get(\"hit_rate\", np.nan),\n",
    "            \"precision_at_k\": eval_metrics_dict.get(\"precision_at_k\", np.nan),\n",
    "            \"recall_at_k\": eval_metrics_dict.get(\"recall_at_k\", np.nan),\n",
    "            \"ndcg_at_k\": eval_metrics_dict.get(\"ndcg_at_k\", np.nan),\n",
    "            \"evaluated_sessions_for_metrics\": eval_metrics_dict.get(\"evaluated_sessions\", 0),\n",
    "            \"error_during_eval\": eval_metrics_dict.get(\"error\", None)\n",
    "        }\n",
    "        performance_records.append(record)\n",
    "\n",
    "    results_summary_df = pd.DataFrame(performance_records)\n",
    "\n",
    "    if not results_summary_df.empty and \"k_for_metrics_calc\" in results_summary_df.columns:\n",
    "        # Ensure there's at least one non-NA k_value to use for renaming\n",
    "        valid_k_values = results_summary_df[\"k_for_metrics_calc\"].dropna()\n",
    "        if not valid_k_values.empty:\n",
    "            actual_k_used = int(valid_k_values.iloc[0])\n",
    "            results_summary_df.rename(columns={\n",
    "                \"precision_at_k\": f\"precision_at_{actual_k_used}\",\n",
    "                \"recall_at_k\": f\"recall_at_{actual_k_used}\",\n",
    "                \"ndcg_at_k\": f\"ndcg_at_{actual_k_used}\",\n",
    "            }, inplace=True)\n",
    "\n",
    "    return results_summary_df\n",
    "\n",
    "if 'CTX_EMPTY_DEMO' not in locals(): CTX_EMPTY_DEMO = {}\n",
    "if 'CTX_ACTION_DEMO' not in locals(): CTX_ACTION_DEMO = {\"Genre\": \"Action\"}\n",
    "if 'CTX_KIDS_G_DEMO' not in locals(): CTX_KIDS_G_DEMO = {\"Rating\": \"G\"}\n",
    "if 'CTX_ENGLISH_NOON_DEMO' not in locals(): CTX_ENGLISH_NOON_DEMO = {\"Language\":\"English\", \"Slot\":\"Noon\"}\n",
    "if 'CTX_ACTION_HINDI_R18_DEMO' not in locals(): CTX_ACTION_HINDI_R18_DEMO = {\"Genre\":\"Action\", \"Language\":\"Hindi\", \"Rating\":\"R18+\"}\n",
    "\n",
    "CONTEXTS_FOR_COMPARISON_TABLE_V2 = [\n",
    "    CTX_EMPTY_DEMO,\n",
    "    CTX_ACTION_DEMO,\n",
    "    CTX_KIDS_G_DEMO,\n",
    "    CTX_ENGLISH_NOON_DEMO,\n",
    "    CTX_ACTION_HINDI_R18_DEMO\n",
    "]\n",
    "\n",
    "if 'PRIMARY_TARGET_ITEM_DEMO' not in locals(): PRIMARY_TARGET_ITEM_DEMO = \"POPCORN\"\n",
    "if 'default_rule_params_demo' not in locals(): default_rule_params_demo = RuleParams()\n",
    "if 'default_rec_gen_params_demo' not in locals(): default_rec_gen_params_demo = RecParams()\n",
    "if 'default_eval_k_param_demo' not in locals() or not isinstance(getattr(locals(), 'default_eval_k_param_demo', None), EvaluationKValueParam):\n",
    "    default_eval_k_param_demo = EvaluationKValueParam(k_for_rank_metrics=5)\n",
    "\n",
    "print(f\"\\n--- Comparing Holdout Performance (Multi-Metric) for Target: {PRIMARY_TARGET_ITEM_DEMO} ---\")\n",
    "if CONTEXTS_FOR_COMPARISON_TABLE_V2:\n",
    "    k_val_for_table_display = default_eval_k_param_demo.k_for_rank_metrics\n",
    "\n",
    "    summary_df_demo_v2 = compare_holdout_performance_across_slices_multi_metric(\n",
    "        data_manager_global,\n",
    "        PRIMARY_TARGET_ITEM_DEMO,\n",
    "        CONTEXTS_FOR_COMPARISON_TABLE_V2,\n",
    "        default_rule_params_demo,\n",
    "        default_rec_gen_params_demo,\n",
    "        EvaluationKValueParam(k_for_rank_metrics=k_val_for_table_display)\n",
    "    )\n",
    "    if not summary_df_demo_v2.empty:\n",
    "        actual_k_val_in_table = 5 # Default if column is missing or all NaN\n",
    "        valid_k_calc_values = summary_df_demo_v2[\"k_for_metrics_calc\"].dropna()\n",
    "        if not valid_k_calc_values.empty:\n",
    "            actual_k_val_in_table = int(valid_k_calc_values.iloc[0])\n",
    "        \n",
    "        formatters = {\n",
    "            \"hit_rate\":\"{:.2%}\",\n",
    "            f\"precision_at_{actual_k_val_in_table}\":\"{:.4f}\",\n",
    "            f\"recall_at_{actual_k_val_in_table}\":\"{:.4f}\",\n",
    "            f\"ndcg_at_{actual_k_val_in_table}\":\"{:.4f}\",\n",
    "            \"target_item_sessions_in_holdout_slice\":\"{:,}\",\n",
    "            \"evaluated_sessions_for_metrics\":\"{:,}\",\n",
    "            \"k_for_metrics_calc\": \"{:d}\"\n",
    "        }\n",
    "        valid_formatters = {k:v for k,v in formatters.items() if k in summary_df_demo_v2.columns}\n",
    "        display(summary_df_demo_v2.style.format(valid_formatters))\n",
    "    else:\n",
    "        print(\"Holdout performance comparison table could not be generated.\")\n",
    "else:\n",
    "    print(\"CONTEXTS_FOR_COMPARISON_TABLE_V2 is empty. Skipping comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db99e7-e537-409b-a1d5-2b81516791a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Building the Master Recommendation Decision Table\n",
    "\n",
    "def build_recommendation_decision_table(\n",
    "    data_mgr: DataManager,\n",
    "    target_item_class_name: str,\n",
    "    list_of_all_contexts: list[dict],\n",
    "    rule_p: RuleParams = RuleParams(),\n",
    "    rec_gen_p: RecParams = RecParams()\n",
    ") -> pd.DataFrame:\n",
    "    decision_table_rows = []\n",
    "    if VERBOSE_LOGGING: print(f\"Building recommendation decision table for target: '{target_item_class_name}'...\")\n",
    "\n",
    "    for context_dict_item in tqdm(list_of_all_contexts, desc=\"Processing Contexts for Decision Table\", leave=False):\n",
    "        context_json_key = json.dumps(context_dict_item, sort_keys=True) if context_dict_item else '{\\\"comment\\\": \\\"Global/No_Context\\\"}'\n",
    "\n",
    "        try:\n",
    "            partner_classes_results_df, sku_recommendations_by_partner_map = generate_recommendations(\n",
    "                data_mgr, target_item_class_name,\n",
    "                context_dict_item, rule_p, rec_gen_p\n",
    "            )\n",
    "        except ValueError as ve:\n",
    "            if VERBOSE_LOGGING: print(f\"Skipping context '{context_json_key}' for decision table due to error: {ve}\")\n",
    "            decision_table_rows.append((\n",
    "                context_json_key, target_item_class_name,\n",
    "                f\"ERROR_PROCESSING_CONTEXT: {str(ve)[:150]}\", None, None, None, None, None # Added None for new cols\n",
    "            ))\n",
    "            continue\n",
    "        except Exception as e_gen_rec:\n",
    "            if VERBOSE_LOGGING: print(f\"Unexpected error for context '{context_json_key}' in decision table: {e_gen_rec}\")\n",
    "            decision_table_rows.append((\n",
    "                context_json_key, target_item_class_name,\n",
    "                f\"UNEXPECTED_ERROR: {str(e_gen_rec)[:150]}\", None, None, None, None, None # Added None for new cols\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        if partner_classes_results_df.empty:\n",
    "            decision_table_rows.append((\n",
    "                context_json_key, target_item_class_name,\n",
    "                \"NO_PARTNER_CLASSES_FOUND\", None, None, None, None, None # Added None for new cols\n",
    "            ))\n",
    "        else:\n",
    "            for _, partner_class_row in partner_classes_results_df.iterrows():\n",
    "                partner_class_name = partner_class_row[\"partner_item_class\"]\n",
    "                partner_class_als_score = partner_class_row[\"class_als_similarity\"]\n",
    "                partner_support = partner_class_row.get(\"support\", np.nan) # Get with default\n",
    "                partner_confidence = partner_class_row.get(\"confidence\", np.nan)\n",
    "                partner_lift = partner_class_row.get(\"lift\", np.nan)\n",
    "\n",
    "\n",
    "                recommended_skus_df = sku_recommendations_by_partner_map.get(partner_class_name)\n",
    "\n",
    "                if recommended_skus_df is None or recommended_skus_df.empty:\n",
    "                    decision_table_rows.append((\n",
    "                        context_json_key, target_item_class_name,\n",
    "                        partner_class_name, partner_support, partner_confidence, partner_lift, partner_class_als_score,\n",
    "                        \"NO_SKUS_RECOMMENDED_FOR_PARTNER\", None\n",
    "                    ))\n",
    "                else:\n",
    "                    for _, sku_row_data in recommended_skus_df.iterrows():\n",
    "                        recommended_sku = sku_row_data[\"recommended_sku_name\"]\n",
    "                        sku_score = sku_row_data[\"sku_als_similarity\"]\n",
    "                        decision_table_rows.append((\n",
    "                            context_json_key, target_item_class_name,\n",
    "                            partner_class_name, partner_support, partner_confidence, partner_lift, partner_class_als_score,\n",
    "                            recommended_sku, sku_score\n",
    "                        ))\n",
    "\n",
    "    final_decision_table_df = pd.DataFrame(\n",
    "        decision_table_rows,\n",
    "        columns=[\n",
    "            \"context_json_representation\", \"target_item_class\",\n",
    "            \"recommended_partner_class\", \"partner_support\", \"partner_confidence\", \"partner_lift\", \"partner_class_als_score\",\n",
    "            \"recommended_partner_sku\", \"partner_sku_als_score\"\n",
    "        ]\n",
    "    )\n",
    "    return final_decision_table_df\n",
    "\n",
    "if 'CONTEXTS_FOR_COMPARISON_TABLE_V2' in locals() and \\\n",
    "   CONTEXTS_FOR_COMPARISON_TABLE_V2 and \\\n",
    "   'PRIMARY_TARGET_ITEM_DEMO' in locals() and \\\n",
    "   'default_rule_params_demo' in locals() and \\\n",
    "   'default_rec_gen_params_demo' in locals():\n",
    "\n",
    "    print(f\"\\n--- Building Master Recommendation Decision Table for Target: {PRIMARY_TARGET_ITEM_DEMO} ---\")\n",
    "    master_table_demo_v2 = build_recommendation_decision_table(\n",
    "        data_manager_global,\n",
    "        PRIMARY_TARGET_ITEM_DEMO,\n",
    "        CONTEXTS_FOR_COMPARISON_TABLE_V2,\n",
    "        default_rule_params_demo,\n",
    "        default_rec_gen_params_demo\n",
    "    )\n",
    "    if not master_table_demo_v2.empty:\n",
    "        print(f\"\\nMaster Table built with {len(master_table_demo_v2)} rows.\")\n",
    "        display(master_table_demo_v2.head(10))\n",
    "\n",
    "        path = MODELS_OUTPUT_DIR / f\"master_recs_{PRIMARY_TARGET_ITEM_DEMO.lower()}_dt_weighted_{CACHE_VERSION_PREFIX.strip('_')}.xlsx\"\n",
    "        try:\n",
    "            master_table_demo_v2.to_excel(path, index=False)\n",
    "            print(f\"Master Table saved to: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving Master Table: {e}\")\n",
    "    else:\n",
    "        print(\"Master Decision Table is empty.\")\n",
    "else:\n",
    "    print(\"Required variables for Master Decision Table are not defined or empty. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18eb04-dc83-4177-9171-9da051b8bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Recommending Top Combos (Function and Demo)\n",
    "\n",
    "def recommend_top_combos(\n",
    "    data_mgr: DataManager, # Added data_mgr argument\n",
    "    ctx: dict,\n",
    "    base: int,\n",
    "    addon: int,\n",
    "    k: int = 10,\n",
    "    p_override: RuleParams = None\n",
    "):\n",
    "    log_context_str = json.dumps(ctx) if ctx else 'Global (No Context)'\n",
    "    log_context_str += f\" (Recency Weighting: {'On' if RECENCY_WEIGHTING_CONFIG['apply'] else 'Off'})\"\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"\\n--- Recommending Top Item Class Combos for context: {log_context_str} ---\")\n",
    "        print(f\"Searching for combos like: ({base} items) -> ({addon} item)\")\n",
    "\n",
    "    required_max_len = base + addon\n",
    "\n",
    "    if p_override is None:\n",
    "        current_p = RuleParams(max_len_global=required_max_len)\n",
    "    else:\n",
    "        current_p = dc_replace(p_override, max_len_global=required_max_len)\n",
    "    \n",
    "    # mine_association_rules_for_context from Cell 4 returns two DataFrames\n",
    "    rules_df, _ = mine_association_rules_for_context(data_mgr, ctx, current_p)\n",
    "\n",
    "    if rules_df.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"No association rules found for context '{log_context_str}' with max_len={required_max_len} for combos.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    combo_df = rules_df[\n",
    "        (rules_df['antecedents'].apply(len) == base) &\n",
    "        (rules_df['consequents'].apply(len) == addon) &\n",
    "        (rules_df['lift'] >= current_p.min_lift) &\n",
    "        (rules_df['confidence'] >= current_p.min_confidence)\n",
    "    ].copy()\n",
    "\n",
    "    if combo_df.empty:\n",
    "        if VERBOSE_LOGGING: print(f\"No combos matching structure found for context '{log_context_str}'.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    class_prefix_to_strip = ITEM_CLASS_PREFIX\n",
    "\n",
    "    def format_itemset_column(itemset_series, prefix_to_strip):\n",
    "        return itemset_series.apply(\n",
    "            lambda s: ', '.join(item.replace(prefix_to_strip, \"\") for item in s) if s else None\n",
    "        )\n",
    "\n",
    "    combo_df['combo_base_items'] = format_itemset_column(combo_df['antecedents'], class_prefix_to_strip)\n",
    "    combo_df['combo_add_on_item'] = format_itemset_column(combo_df['consequents'], class_prefix_to_strip)\n",
    "\n",
    "    ranked_combos_df = combo_df.sort_values(\n",
    "        by=['lift', 'confidence'], ascending=[False, False]\n",
    "    ).head(k)\n",
    "\n",
    "    return ranked_combos_df[['combo_base_items', 'combo_add_on_item', 'lift', 'confidence', 'support']]\n",
    "\n",
    "if 'CTX_KIDS_G_DEMO' not in locals(): CTX_KIDS_G_DEMO = {\"Rating\": \"G\"}\n",
    "if 'CTX_EMPTY_DEMO' not in locals(): CTX_EMPTY_DEMO = {}\n",
    "if 'CTX_ENGLISH_NOON_DEMO' not in locals(): CTX_ENGLISH_NOON_DEMO = {\"Language\":\"English\", \"Slot\":\"Noon\"}\n",
    "\n",
    "if CTX_KIDS_G_DEMO is not None:\n",
    "    print(f\"\\n--- Finding Top Combos (Buy 2 Get 1 type) for Context: {json.dumps(CTX_KIDS_G_DEMO)} ---\")\n",
    "    kids_g_combos_b2g1_df = recommend_top_combos(\n",
    "        data_manager_global,\n",
    "        ctx=CTX_KIDS_G_DEMO,\n",
    "        base=2, addon=1, k=5\n",
    "    )\n",
    "    if not kids_g_combos_b2g1_df.empty: display(kids_g_combos_b2g1_df)\n",
    "    else: print(f\"No (Buy 2 Get 1 type) combos found for {CTX_KIDS_G_DEMO} context.\")\n",
    "else:\n",
    "    print(\"CTX_KIDS_G_DEMO not defined. Skipping combo demo.\")\n",
    "\n",
    "print(f\"\\n--- Finding Top Combos (Buy 1 Get 2 type) Overall (No Context) ---\")\n",
    "overall_combos_b1g2_df = recommend_top_combos(\n",
    "    data_manager_global,\n",
    "    ctx=CTX_EMPTY_DEMO, base=1, addon=2, k=5\n",
    ")\n",
    "if not overall_combos_b1g2_df.empty: display(overall_combos_b1g2_df)\n",
    "else: print(\"No (Buy 1 Get 2 type) combos found for overall dataset.\")\n",
    "\n",
    "if 'CTX_ENGLISH_NOON_DEMO' in locals() and CTX_ENGLISH_NOON_DEMO is not None:\n",
    "    print(f\"\\n--- Finding Top Pairs (Buy 1 Get 1 type) for Context: {json.dumps(CTX_ENGLISH_NOON_DEMO)} ---\")\n",
    "    eng_noon_pairs_df = recommend_top_combos(\n",
    "        data_manager_global,\n",
    "        ctx=CTX_ENGLISH_NOON_DEMO, base=1, addon=1, k=5\n",
    "    )\n",
    "    if not eng_noon_pairs_df.empty: display(eng_noon_pairs_df)\n",
    "    else: print(f\"No (Buy 1 Get 1 type) pairs found for {CTX_ENGLISH_NOON_DEMO} context.\")\n",
    "else:\n",
    "    print(\"CTX_ENGLISH_NOON_DEMO not defined. Skipping pair demo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c813f5-c39a-44db-90ac-c70b55a37ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Pre-caching Script\n",
    "\n",
    "def pre_cache_models_and_rules_for_contexts(\n",
    "    data_mgr: DataManager,\n",
    "    list_of_contexts_to_cache: list[dict],\n",
    "    standard_rule_p: RuleParams, \n",
    "    combo_rule_p: RuleParams \n",
    "):\n",
    "    print(f\"--- Starting Pre-caching for {len(list_of_contexts_to_cache)} Contexts ---\")\n",
    "    for i, context_to_cache in enumerate(list_of_contexts_to_cache):\n",
    "        log_context_str = json.dumps(context_to_cache) if context_to_cache else 'Global (No Context)'\n",
    "        print(f\"\\n({i+1}/{len(list_of_contexts_to_cache)}) Caching for context: {log_context_str}\")\n",
    "        try:\n",
    "            if VERBOSE_LOGGING: print(\"  Caching standard association rules...\")\n",
    "            mine_association_rules_for_context(data_mgr, context_to_cache, standard_rule_p)\n",
    "            \n",
    "            if VERBOSE_LOGGING: print(\"  Caching association rules for combo mining (potentially different params)...\")\n",
    "            # If combo_rule_p is for different max_len, this will create a different cache file.\n",
    "            mine_association_rules_for_context(data_mgr, context_to_cache, combo_rule_p)\n",
    "            \n",
    "            if VERBOSE_LOGGING: print(\"  Caching ALS models...\")\n",
    "            load_context_specific_als_models(data_mgr, context_to_cache)\n",
    "            \n",
    "            if VERBOSE_LOGGING: print(f\"  â Successfully processed caching tasks for context: {log_context_str}\")\n",
    "        except ValueError as ve:\n",
    "            print(f\"  SKIPPING context {log_context_str} due to ValueError: {ve}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR during caching for context {log_context_str}: {e}\")\n",
    "    print(\"\\n--- Pre-caching Process Complete ---\")\n",
    "\n",
    "# RuleParams from Cell 2 includes max_itemset_len_segment, which is used by mine_association_rules_for_context\n",
    "standard_rules_for_precache_final = RuleParams(\n",
    "    max_len_global=0, # For general pair rules often, or no limit\n",
    "    max_itemset_len_segment=2 # For 1-to-1 segment specific rules\n",
    ")\n",
    "combo_rules_for_precache_final = RuleParams(\n",
    "    max_len_global=3, # For (A,B)->C or A->(B,C)\n",
    "    max_itemset_len_segment=2 # Or 0 if segment combos aren't needed/mined differently\n",
    ")\n",
    "\n",
    "if 'CONTEXTS_FOR_COMPARISON_TABLE_V2' in locals() and CONTEXTS_FOR_COMPARISON_TABLE_V2:\n",
    "    if VERBOSE_LOGGING:\n",
    "        print(f\"\\nTotal unique contexts identified for pre-caching: {len(CONTEXTS_FOR_COMPARISON_TABLE_V2)}\")\n",
    "    \n",
    "    print(\"\\nInitiating pre-caching process. This may take a significant amount of time...\")\n",
    "    print(\"This will attempt to cache rules and ALS models for the specified contexts using recency weighting.\")\n",
    "    pre_cache_models_and_rules_for_contexts(\n",
    "        data_manager_global,\n",
    "        CONTEXTS_FOR_COMPARISON_TABLE_V2,\n",
    "        standard_rule_p=standard_rules_for_precache_final,\n",
    "        combo_rule_p=combo_rules_for_precache_final\n",
    "    )\n",
    "    print(\"\\nPre-caching script is ready. Uncomment the call to `pre_cache_models_and_rules_for_contexts` to run.\")\n",
    "else:\n",
    "    if VERBOSE_LOGGING: print(\"CONTEXTS_FOR_COMPARISON_TABLE_V2 not defined or empty. Pre-caching script demo will not run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ed796-4974-4e59-9255-f4fb7e6a6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Enhanced Visualizations for Stakeholders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"matplotlib.text\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.formatter.limits'] = -5, 5\n",
    "\n",
    "print(\"\\n--- Enhanced Visualizations for Stakeholder Review (Recency Weighted) ---\")\n",
    "\n",
    "if 'PRIMARY_TARGET_ITEM_DEMO' not in locals(): PRIMARY_TARGET_ITEM_DEMO = \"POPCORN\" # Ensure it's defined\n",
    "\n",
    "if 'summary_df_demo_v2' in locals() and isinstance(summary_df_demo_v2, pd.DataFrame) and not summary_df_demo_v2.empty:\n",
    "    print(\"\\n--- 1. Recommendation Performance Across Contexts ---\")\n",
    "    df_perf = summary_df_demo_v2.copy()\n",
    "    \n",
    "    def shorten_context(desc):\n",
    "        if desc == \"Global (No Context)\": return \"Global\"\n",
    "        try:\n",
    "            if isinstance(desc, str) and desc.startswith(\"{\") and desc.endswith(\"}\"):\n",
    "                ctx_dict = json.loads(desc)\n",
    "                return \"\\n\".join([f\"{k}: { (','.join(map(str,v)) if isinstance(v,list) else str(v)) }\" for k,v in ctx_dict.items()])\n",
    "            return textwrap.fill(str(desc), width=25)\n",
    "        except json.JSONDecodeError:\n",
    "            return textwrap.fill(str(desc), width=25)\n",
    "\n",
    "    df_perf['short_context'] = df_perf['context_description'].apply(shorten_context)\n",
    "    \n",
    "    k_val_for_plot = 5\n",
    "    valid_k_values = df_perf[\"k_for_metrics_calc\"].dropna()\n",
    "    if not valid_k_values.empty:\n",
    "        k_val_for_plot = int(valid_k_values.iloc[0])\n",
    "\n",
    "    precision_col = f\"precision_at_{k_val_for_plot}\"\n",
    "    recall_col = f\"recall_at_{k_val_for_plot}\"\n",
    "    ndcg_col = f\"ndcg_at_{k_val_for_plot}\"\n",
    "\n",
    "    metrics_to_plot = ['hit_rate', precision_col, recall_col]\n",
    "    existing_metrics_to_plot = [m for m in metrics_to_plot if m in df_perf.columns]\n",
    "\n",
    "    if existing_metrics_to_plot:\n",
    "        df_melted = pd.melt(df_perf, id_vars=['short_context'], value_vars=existing_metrics_to_plot,\n",
    "                            var_name='Metric', value_name='Score')\n",
    "        df_melted['Score'] = pd.to_numeric(df_melted['Score'], errors='coerce')\n",
    "        df_melted.dropna(subset=['Score'], inplace=True)\n",
    "\n",
    "        if not df_melted.empty:\n",
    "            plt.figure()\n",
    "            ax = sns.barplot(data=df_melted, x='short_context', y='Score', hue='Metric', palette='viridis')\n",
    "            plt.title(f\"Key Recommendation Metrics for Target '{PRIMARY_TARGET_ITEM_DEMO}' (Top {k_val_for_plot} Recs)\", fontsize=16, pad=20)\n",
    "            plt.xlabel(\"Context\", fontsize=14, labelpad=15)\n",
    "            plt.ylabel(\"Metric Score\", fontsize=14, labelpad=15)\n",
    "            plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            \n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            ax.legend(handles, labels, title='Metric', title_fontsize='13', fontsize='11', loc='best')\n",
    "\n",
    "            for i, container in enumerate(ax.containers):\n",
    "                metric_name_for_format = labels[i]\n",
    "                for bar in container.patches:\n",
    "                    height = float(bar.get_height())\n",
    "                    if pd.isna(height) or abs(height) < 0.00001: continue\n",
    "                    if \"hit_rate\" in metric_name_for_format.lower():\n",
    "                        label_text = f\"{height:.1%}\"\n",
    "                    else:\n",
    "                        label_text = f\"{height:.3f}\"\n",
    "                    ax.annotate(label_text,\n",
    "                                xy=(float(bar.get_x() + bar.get_width() / 2), height),\n",
    "                                xytext=(0, 3), textcoords=\"offset points\",\n",
    "                                ha='center', va='bottom', fontsize=8, color='black')\n",
    "            plt.ylim(top=df_melted['Score'].max() * 1.18 if not df_melted['Score'].empty and pd.notna(df_melted['Score'].max()) else 0.1)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Melted DataFrame for bar plot is empty or all scores are NaN.\")\n",
    "    else:\n",
    "        print(f\"None of the metrics {metrics_to_plot} found in performance summary for bar plot.\")\n",
    "\n",
    "    if ndcg_col in df_perf.columns:\n",
    "        plt.figure()\n",
    "        df_perf[ndcg_col] = pd.to_numeric(df_perf[ndcg_col], errors='coerce')\n",
    "        df_plot_ndcg = df_perf.dropna(subset=[ndcg_col])\n",
    "\n",
    "        if not df_plot_ndcg.empty:\n",
    "            sns.lineplot(data=df_plot_ndcg, x='short_context', y=ndcg_col, marker='o', sort=False, color='crimson', linewidth=2.5)\n",
    "            plt.title(f\"NDCG@{k_val_for_plot} for Target '{PRIMARY_TARGET_ITEM_DEMO}' across Contexts\", fontsize=16, pad=20)\n",
    "            plt.xlabel(\"Context\", fontsize=14, labelpad=15)\n",
    "            plt.ylabel(f\"NDCG@{k_val_for_plot}\", fontsize=14, labelpad=15)\n",
    "            plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            for _, row in df_plot_ndcg.iterrows():\n",
    "                if pd.notna(row[ndcg_col]):\n",
    "                    x_pos = row['short_context']\n",
    "                    y_pos = float(row[ndcg_col])\n",
    "                    plt.text(x_pos, y_pos, f\"{y_pos:.3f}\", color='black', ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"No valid data for NDCG plot after handling NaNs for column '{ndcg_col}'.\")\n",
    "    else:\n",
    "        print(f\"Column '{ndcg_col}' not found for NDCG plot.\")\n",
    "else:\n",
    "    print(\"Performance summary DataFrame ('summary_df_demo_v2') not found or empty. Skipping performance visualizations.\")\n",
    "\n",
    "if 'partner_classes_df_action' in locals() and 'sku_map_action' in locals() and \\\n",
    "   'PRIMARY_TARGET_ITEM_DEMO' in locals() and \\\n",
    "   isinstance(partner_classes_df_action, pd.DataFrame) and not partner_classes_df_action.empty:\n",
    "    \n",
    "    print(f\"\\n--- 2. Deep Dive: '{PRIMARY_TARGET_ITEM_DEMO}' Recommendations in 'Action' Context ---\")\n",
    "    \n",
    "    df_pc_action = partner_classes_df_action.copy()\n",
    "    als_col_name = 'class_als_similarity'\n",
    "\n",
    "    if 'lift' in df_pc_action.columns and als_col_name in df_pc_action.columns and 'partner_item_class' in df_pc_action.columns:\n",
    "        fig, ax1 = plt.subplots()\n",
    "        color_lift = 'tab:blue'\n",
    "        ax1.set_xlabel('Partner Item Class', fontsize=14, labelpad=15)\n",
    "        ax1.set_ylabel('Lift', color=color_lift, fontsize=14, labelpad=15)\n",
    "        df_pc_action['lift'] = pd.to_numeric(df_pc_action['lift'], errors='coerce')\n",
    "        plot_df_pc_lift = df_pc_action.dropna(subset=['lift', 'partner_item_class'])\n",
    "\n",
    "        if not plot_df_pc_lift.empty:\n",
    "            bars = ax1.bar(plot_df_pc_lift['partner_item_class'], plot_df_pc_lift['lift'], color=color_lift, alpha=0.7, label='Lift')\n",
    "            ax1.tick_params(axis='y', labelcolor=color_lift)\n",
    "            ax1.set_xticks(range(len(plot_df_pc_lift['partner_item_class'])))\n",
    "            ax1.set_xticklabels(plot_df_pc_lift['partner_item_class'], rotation=30, ha=\"right\", fontsize=10)\n",
    "            for bar_patch in bars:\n",
    "                yval = float(bar_patch.get_height())\n",
    "                if pd.notna(yval):\n",
    "                     plt.text(float(bar_patch.get_x() + bar_patch.get_width()/2.0), yval, f'{yval:.2f}', va='bottom', ha='center', fontsize=9)\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        color_als = 'tab:red'\n",
    "        ax2.set_ylabel(f'ALS Similarity', color=color_als, fontsize=14, labelpad=15)\n",
    "        df_pc_action[als_col_name] = pd.to_numeric(df_pc_action[als_col_name], errors='coerce')\n",
    "        plot_df_pc_als = df_pc_action.dropna(subset=[als_col_name, 'partner_item_class'])\n",
    "\n",
    "        if not plot_df_pc_als.empty:\n",
    "            ax2.plot(range(len(plot_df_pc_als['partner_item_class'])), plot_df_pc_als[als_col_name], color=color_als, marker='o', linestyle='--', linewidth=2, label=f'ALS Similarity')\n",
    "            ax2.tick_params(axis='y', labelcolor=color_als)\n",
    "            for idx_row, row_als in plot_df_pc_als.iterrows(): # Use idx_row for index\n",
    "                if pd.notna(row_als[als_col_name]):\n",
    "                    try:\n",
    "                        text_x_pos = list(plot_df_pc_lift['partner_item_class']).index(row_als['partner_item_class'])\n",
    "                        ax2.text(text_x_pos, float(row_als[als_col_name]), f\"{float(row_als[als_col_name]):.3f}\", color=color_als, ha=\"left\", va=\"bottom\", fontsize=9)\n",
    "                    except ValueError: pass\n",
    "        fig.tight_layout(rect=[0, 0.05, 1, 0.93])\n",
    "        plt.title(f\"Top Partner Classes for '{PRIMARY_TARGET_ITEM_DEMO}' (Action Context) \\nby Lift & ALS Similarity\", fontsize=16, pad=20)\n",
    "        handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "        handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "        if handles1 or handles2: ax1.legend(handles1 + handles2, labels1 + labels2, loc='best')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Required columns for deep dive plot not found in 'partner_classes_df_action'.\")\n",
    "\n",
    "    if sku_map_action and isinstance(sku_map_action, dict):\n",
    "        first_partner_with_skus = None\n",
    "        first_skus_df = None\n",
    "        ordered_partners_from_df = df_pc_action['partner_item_class'].tolist() if 'partner_item_class' in df_pc_action.columns else list(sku_map_action.keys())\n",
    "        for partner_name in ordered_partners_from_df:\n",
    "            if partner_name in sku_map_action and isinstance(sku_map_action[partner_name], pd.DataFrame) and not sku_map_action[partner_name].empty:\n",
    "                first_partner_with_skus = partner_name\n",
    "                first_skus_df = sku_map_action[partner_name].copy()\n",
    "                break\n",
    "        \n",
    "        if first_partner_with_skus and first_skus_df is not None:\n",
    "            plt.figure()\n",
    "            sku_als_col = 'sku_als_similarity'\n",
    "            if sku_als_col in first_skus_df.columns and 'recommended_sku_name' in first_skus_df.columns:\n",
    "                first_skus_df[sku_als_col] = pd.to_numeric(first_skus_df[sku_als_col], errors='coerce')\n",
    "                plot_df_skus = first_skus_df.dropna(subset=[sku_als_col])\n",
    "                if not plot_df_skus.empty:\n",
    "                    ax_sku = sns.barplot(data=plot_df_skus, x=\"recommended_sku_name\", y=sku_als_col, \n",
    "                                         hue=\"recommended_sku_name\", palette=\"crest\", legend=False)\n",
    "                    plt.title(f\"Top SKU ALS Similarity for Partner '{first_partner_with_skus}'\\n(Target: {PRIMARY_TARGET_ITEM_DEMO}, Context: Action)\", fontsize=16, pad=20)\n",
    "                    plt.xlabel(\"Recommended SKU\", fontsize=14, labelpad=15)\n",
    "                    plt.ylabel(\"SKU ALS Similarity\", fontsize=14, labelpad=15)\n",
    "                    plt.xticks(rotation=30, ha=\"right\", fontsize=10); plt.yticks(fontsize=10)\n",
    "                    for p_bar in ax_sku.patches:\n",
    "                        height = float(p_bar.get_height())\n",
    "                        if pd.notna(height):\n",
    "                            ax_sku.annotate(f\"{height:.3f}\",\n",
    "                                        (float(p_bar.get_x() + p_bar.get_width() / 2.), height),\n",
    "                                        ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),\n",
    "                                        textcoords='offset points')\n",
    "                    plt.tight_layout(); plt.show()\n",
    "                else:\n",
    "                    print(f\"No valid SKU data to plot for partner '{first_partner_with_skus}'.\")\n",
    "            else:\n",
    "                 print(f\"Required columns for SKU plot not found for partner '{first_partner_with_skus}'.\")\n",
    "        else:\n",
    "            print(\"No SKU data found in 'sku_map_action' for detailed partner visualization.\")\n",
    "else:\n",
    "    print(\"Data for 'Action' context recommendations not found. Skipping deep dive visualizations.\")\n",
    "\n",
    "if 'overall_combos_b1g2_df' in locals() and isinstance(overall_combos_b1g2_df, pd.DataFrame) and not overall_combos_b1g2_df.empty:\n",
    "    print(\"\\n--- 3. Combo Recommendation Insights (Overall: Buy 1 Base -> Get 2 Add-on) ---\")\n",
    "    df_combo = overall_combos_b1g2_df.copy()\n",
    "    base_col = 'combo_base_items'\n",
    "    addon_col = 'combo_add_on_item'\n",
    "\n",
    "    if base_col in df_combo.columns and addon_col in df_combo.columns and 'lift' in df_combo.columns and 'confidence' in df_combo.columns:\n",
    "        df_combo['full_combo_str'] = df_combo[base_col].astype(str) + \" â \" + df_combo[addon_col].astype(str)\n",
    "        df_combo['full_combo_str_wrapped'] = df_combo['full_combo_str'].apply(lambda x: textwrap.fill(x, width=45))\n",
    "        df_combo['lift'] = pd.to_numeric(df_combo['lift'], errors='coerce')\n",
    "        df_combo['confidence'] = pd.to_numeric(df_combo['confidence'], errors='coerce')\n",
    "        plot_df_combo = df_combo.dropna(subset=['lift', 'confidence'])\n",
    "\n",
    "        if not plot_df_combo.empty:\n",
    "            plt.figure(figsize=(12,8))\n",
    "            ax_combo = sns.barplot(data=plot_df_combo.head(10), y='full_combo_str_wrapped', x='lift', \n",
    "                                   hue='full_combo_str_wrapped', palette='magma', orient='h', legend=False)\n",
    "            plt.title(f\"Top 'Buy 1 Base -> Get 2 Add-on' Item Class Combos by Lift (Overall Context)\", fontsize=16, pad=20)\n",
    "            plt.xlabel(\"Lift\", fontsize=14, labelpad=15)\n",
    "            plt.ylabel(\"Combo (Base â Add-on)\", fontsize=14, labelpad=15)\n",
    "            plt.xticks(fontsize=10); plt.yticks(fontsize=9)\n",
    "            for i, bar_patch in enumerate(ax_combo.patches):\n",
    "                value = float(bar_patch.get_width())\n",
    "                confidence_val = float(plot_df_combo.head(10)['confidence'].iloc[i])\n",
    "                if pd.notna(value) and pd.notna(confidence_val):\n",
    "                    label_text = f\"Lift: {value:.2f}\\nConf: {confidence_val:.1%}\"\n",
    "                    ax_combo.text(value + 0.02, float(bar_patch.get_y() + bar_patch.get_height() / 2), \n",
    "                                  label_text, va='center', ha='left', fontsize=8, color='black')\n",
    "            max_lift = plot_df_combo['lift'].max()\n",
    "            plt.xlim(right=max_lift * 1.25 if pd.notna(max_lift) and max_lift > 0 else 1.5)\n",
    "            plt.tight_layout(); plt.show()\n",
    "        else:\n",
    "            print(\"No valid data for combo plot after handling NaNs.\")\n",
    "    else:\n",
    "        print(\"Required columns for combo plot not found in 'overall_combos_b1g2_df'.\")\n",
    "else:\n",
    "    print(\"Combo DataFrame ('overall_combos_b1g2_df') not found or empty. Skipping combo visualizations.\")\n",
    "\n",
    "if 'master_table_demo_v2' in locals() and isinstance(master_table_demo_v2, pd.DataFrame) and not master_table_demo_v2.empty:\n",
    "    print(\"\\n--- 4. Distribution of Partner Class ALS Scores from Master Table ---\")\n",
    "    df_master = master_table_demo_v2.copy()\n",
    "    als_partner_col = 'partner_class_als_score'\n",
    "\n",
    "    if als_partner_col in df_master.columns:\n",
    "        als_scores_partner = pd.to_numeric(df_master[als_partner_col], errors='coerce').dropna()\n",
    "        if not als_scores_partner.empty:\n",
    "            plt.figure()\n",
    "            sns.histplot(als_scores_partner, kde=True, color='darkcyan', bins=20)\n",
    "            plt.title(f\"Distribution of Partner Class ALS Scores (Target: {PRIMARY_TARGET_ITEM_DEMO})\", fontsize=16, pad=20)\n",
    "            plt.xlabel(\"Partner Class ALS Score\", fontsize=14, labelpad=15)\n",
    "            plt.ylabel(\"Frequency\", fontsize=14, labelpad=15)\n",
    "            plt.xticks(fontsize=10); plt.yticks(fontsize=10)\n",
    "            plt.tight_layout(); plt.show()\n",
    "            \n",
    "            global_context_key = '{\\\"comment\\\": \\\"Global/No_Context\\\"}'\n",
    "            df_global_recs = df_master[df_master['context_json_representation'] == global_context_key].copy()\n",
    "            sku_als_col_master = 'partner_sku_als_score'\n",
    "            partner_col_master = 'recommended_partner_class'\n",
    "\n",
    "            if sku_als_col_master in df_global_recs.columns and partner_col_master in df_global_recs.columns:\n",
    "                df_global_recs[sku_als_col_master] = pd.to_numeric(df_global_recs[sku_als_col_master], errors='coerce')\n",
    "                df_global_recs.dropna(subset=[partner_col_master, sku_als_col_master], inplace=True)\n",
    "                df_global_recs = df_global_recs[~df_global_recs[partner_col_master].astype(str).str.contains(\"NO_PARTNER|ERROR\", na=False)]\n",
    "\n",
    "                if not df_global_recs.empty:\n",
    "                    unique_partners = df_global_recs[partner_col_master].unique()\n",
    "                    if len(unique_partners) > 10:\n",
    "                        top_partners_for_boxplot = df_global_recs[partner_col_master].value_counts().nlargest(7).index\n",
    "                        df_plot_skus_master = df_global_recs[df_global_recs[partner_col_master].isin(top_partners_for_boxplot)]\n",
    "                        boxplot_title_suffix = \"(Top 7 Partners by Freq.)\"\n",
    "                    else:\n",
    "                        df_plot_skus_master = df_global_recs\n",
    "                        boxplot_title_suffix = \"\"\n",
    "\n",
    "                    if not df_plot_skus_master.empty:\n",
    "                        plt.figure(figsize=(15,8))\n",
    "                        sns.boxplot(data=df_plot_skus_master, x=partner_col_master, y=sku_als_col_master, \n",
    "                                    hue=partner_col_master, palette='pastel', legend=False,\n",
    "                                    order = df_plot_skus_master.groupby(partner_col_master)[sku_als_col_master].median().sort_values(ascending=False).index)\n",
    "                        plt.title(f\"Distribution of SKU ALS Scores per Partner Class {boxplot_title_suffix}\\n(Global Context, Target: {PRIMARY_TARGET_ITEM_DEMO})\", fontsize=16, pad=20)\n",
    "                        plt.xlabel(\"Recommended Partner Class\", fontsize=14, labelpad=15)\n",
    "                        plt.ylabel(\"SKU ALS Score\", fontsize=14, labelpad=15)\n",
    "                        plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "                        plt.yticks(fontsize=10)\n",
    "                        plt.tight_layout(); plt.show()\n",
    "                    else:\n",
    "                        print(\"Not enough data for SKU ALS score boxplot from master table.\")\n",
    "                else:\n",
    "                    print(\"No valid global context recommendations in master table for SKU boxplot.\")\n",
    "            else:\n",
    "                print(\"Required columns for SKU ALS score boxplot not found in master table's global data.\")\n",
    "        else:\n",
    "            print(\"No valid Partner Class ALS scores in master table for distribution plot.\")\n",
    "    else:\n",
    "        print(f\"Column '{als_partner_col}' for partner ALS scores not found in master table.\")\n",
    "else:\n",
    "    print(\"Master decision table ('master_table_demo_v2') not found or empty. Skipping master table visualizations.\")\n",
    "\n",
    "print(\"\\n--- End of Enhanced Visualizations ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
